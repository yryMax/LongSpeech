{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T02:19:31.036735Z",
     "start_time": "2025-07-28T02:19:30.737466Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import typing\n",
    "from langdetect import detect, LangDetectException\n",
    "from pathlib import Path\n",
    "from openai.types.chat import ChatCompletion\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "\n",
    "import asyncio\n",
    "import aiofiles \n",
    "from openai import AsyncOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75c130cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_openai_translation(\n",
    "    completion: ChatCompletion,\n",
    "    target_lang: str = 'en',\n",
    "    min_completion_tokens: int = 100\n",
    ") -> bool:\n",
    "    try:\n",
    "        if not completion or not completion.choices:\n",
    "            return False\n",
    "\n",
    "        first_choice = completion.choices[0]\n",
    "\n",
    "        if first_choice.finish_reason != 'stop':\n",
    "            return False\n",
    "\n",
    "        if not completion.usage or completion.usage.completion_tokens < min_completion_tokens:\n",
    "            return False\n",
    "\n",
    "        content = first_choice.message.content\n",
    "        if not content:\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            answer_lang = detect(content)\n",
    "            if target_lang.lower() != answer_lang.lower():\n",
    "                return False\n",
    "        except LangDetectException:\n",
    "            return False\n",
    "\n",
    "    except AttributeError as e:\n",
    "        return False\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6fbc337",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = {\n",
    "  \"en\": \"Translate the text provided by the user after the `###` delimiter into English. Output only the translated text.\",\n",
    "  \"de\": \"Übersetzen Sie den Text, den der Benutzer nach dem `###`-Trennzeichen bereitstellt, ins Deutsche. Geben Sie nur den übersetzten Text aus.\",\n",
    "  \"fr\": \"Traduisez le texte fourni par l'utilisateur après le délimiteur `###` en français. Ne retournez que le texte traduit.\",\n",
    "  \"zh-CN\": \"将用户在 `###` 分隔符后提供的文本翻译成简体中文。只输出翻译后的文本。\",\n",
    "  \"es\": \"Traduzca el texto proporcionado por el usuario después del delimitador `###` al español. Devuelva únicamente el texto traducido.\",\n",
    "  \"it\": \"Traduci il testo fornito dall'utente dopo il delimitatore `###` in italiano. Restituisci solo il testo tradotto.\",\n",
    "  \"pl\": \"Przetłumacz tekst dostarczony przez użytkownika po ograniczniku `###` na język polski. Zwróć tylko przetłumaczony tekst.\",\n",
    "  \"ro\": \"Traduceți textul furnizat de utilizator după delimitatorul `###` în limba română. Afișați doar textul tradus.\",\n",
    "  \"ja\": \"ユーザーが`###`デリミタの後に提供したテキストを日本語に翻訳してください。翻訳されたテキストのみを出力してください。\",\n",
    "  \"hu\": \"Fordítsa le a felhasználó által a `###` elválasztójel után megadott szöveget magyarra. Csak a lefordított szöveget adja vissza.\",\n",
    "  \"cs\": \"Přeložte text poskytnutý uživatelem po oddělovači `###` do češtiny. Vypište pouze přeložený text.\",\n",
    "  \"tr\": \"Kullanıcı tarafından `###` sınırlayıcısından sonra sağlanan metni Türkçe'ye çevirin. Yalnızca çevrilmiş metni çıktı olarak verin.\",\n",
    "  \"nl\": \"Vertaal de tekst die de gebruiker na het `###`-scheidingsteken verstrekt naar het Nederlands. Geef alleen de vertaalde tekst terug.\",\n",
    "  \"th\": \"โปรดแปลข้อความที่ผู้ใช้ป้อนหลังตัวคั่น `###` เป็นภาษาไทย และแสดงผลเฉพาะข้อความที่แปลแล้วเท่านั้น\",\n",
    "  \"id\": \"Terjemahkan teks yang diberikan oleh pengguna setelah pembatas `###` ke dalam bahasa Indonesia. Hanya keluarkan teks yang sudah diterjemahkan.\",\n",
    "  \"vi\": \"Dịch văn bản do người dùng cung cấp sau dấu phân cách `###` sang tiếng Việt. Chỉ xuất ra văn bản đã dịch.\",\n",
    "  \"ko\": \"`###` 구분 기호 뒤에 사용자가 제공한 텍스트를 한국어로 번역하십시오. 번역된 텍스트만 출력하십시오.\"\n",
    "}\n",
    "openai.api_key = 'aib_machinetranslation_a6a051'\n",
    "openai.base_url = \"https://pre-openai-keys.alibaba-inc.com\"\n",
    "model_name= \"gpt-4o-mini\"\n",
    "possible_langs = list(system_prompt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "832975c9c8d1d81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T02:25:42.540172Z",
     "start_time": "2025-07-28T02:25:22.921340Z"
    }
   },
   "outputs": [],
   "source": [
    "def openai_translate_one(lang, content):\n",
    "    completion = openai.chat.completions.create(\n",
    "\n",
    "        model=model_name,\n",
    "\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt[lang]},\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"###\" +  content +  \"###\"\n",
    "        },\n",
    "        ],\n",
    "        #max_tokens=100,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0,\n",
    "        n=1\n",
    "    )\n",
    "    if validate_openai_translation(completion, lang, 100):\n",
    "        return completion.choices[0].message.content.replace(\"#\", \"\"), completion.usage.total_tokens\n",
    "    else:\n",
    "        print(\"garbage response\")\n",
    "        return None, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3576f04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('这件事发生在一个异常乏味的时期，因此可能吸引了比它应得的更多的关注，但它向公众提供了一种奇异与悲剧的混合，这对大众想象力最具刺激性。然而，经过几周的无果调查，当发现没有最终的事实解释时，兴趣便开始减退，悲剧似乎从那时起就开始了。也许我应该刷新一下他们的记忆，回顾一下这篇评论所依据的奇特事实。这些事实简要如下：在我提到的那年三月十八日下午五点，一列火车从尤斯顿车站开往曼彻斯特。那是一个下着雨、风暴交加的日子，随着时间的推移天气变得更加恶劣，因此在这种天气下，除了出于必要，没人会选择出行。然而，这列火车在曼彻斯特的商人中非常受欢迎，因为它只需四小时二十分钟就能完成旅程，中途仅停靠三次。尽管傍晚天气恶劣，但车厢内仍然相对满员。在我提到的那次出行中，列车的列车员是一位为公司工作了二十二年的老员工，他没有任何污点或投诉。他的名字是约翰·帕尔默。车站的钟敲响五点，列车员正准备向机车司机发出常规信号时，他注意到两名迟到的乘客急匆匆地朝站台走来。其中一位是一位身材特别高大的男士，穿着一件带有阿斯特拉罕毛领和袖口的黑色长外套。我已经提到过，傍晚的天气很糟糕，而这位高个旅客的高领子翻起来，以保护他的喉咙免受刺骨的三月寒风的侵袭。根据列车员匆忙的观察，他似乎是一位五十至六十岁之间的男士。与他同行的女士则显得相对矮小，她穿着一件长长的淡褐色防尘斗篷，戴着一顶黑色贴身小帽，脸上蒙着一层黑色面纱，遮住了大部分面容。这两人很可能被误认为是父女。他们迅速沿着车厢走，朝窗户里望去，直到列车员约翰·帕尔默追上了他们。 “快点，先生，火车要开了，”他说。 “一等座，”那位男士回答。列车员转动了最近一扇门的把手，打开了车厢，里面坐着一位嘴里叼着雪茄的小个子男子。他的外貌似乎在列车员的记忆中留下了深刻印象，因为他后来能够描述或识别出他。这位男士大约三十四或三十五岁，穿着一些灰色的材料，尖鼻子，机警，脸色红润，显得风吹日晒。他在门打开时抬头看了一眼。高个子男士停在了台阶上。“这是吸烟车厢。女士不喜欢烟雾。” “好的，您在这里，”约翰·帕尔默说。他关上了吸烟车厢的门，打开了下一个空车厢的门，把两位旅客推了进去。与此同时，他吹响了口哨，火车的轮子开始移动。那位叼着雪茄的男子在他的车厢窗边对列车员说了些什么，但由于出发时的喧闹，话语被淹没了。帕尔默走进了列车员的货车，随即不再关注这一事件。在离开后十二分钟，火车到达威尔斯登交汇站，停留了非常短暂的时间。对车票的检查确认，没有人此时上车或下车，平台上没有乘客被看到下车。在五点十四分，前往曼彻斯特的旅程恢复，六点五十分到达拉格比。由于在拉格比时快车晚点五分钟，车站工作人员注意到一等车厢的一扇门是开着的。对该车厢及其邻近车厢的检查揭示了一种异常的情况：在吸烟车厢里，那个短小的红脸男子除了半根烟斗外，完全没有其最近乘客的痕迹。这个车厢的门是锁上的，而引起最初注意的下一个车厢则没有那位阿斯特拉罕领的绅士或陪伴他的年轻女士的任何迹象。所有三名乘客都消失了。另一方面，在这辆高个旅客和那位女士曾经乘坐的车厢地板上，发现了一名年轻男子，他穿着时尚，外表优雅。他的膝盖和一个手肘都搭在座位上，一颗子弹穿透了他的心脏，他的死亡必定是瞬间的。没有人看到这样的男子上车，他的口袋里也没有发现火车票。至于从威尔斯登出发一个半小时前的那三个人发生了什么，我已提到过，没有任何可能帮助识别他的个人财物。但确实有一点关于这位不知名的年轻男子的特殊之处在当时受到广泛讨论：他的口袋里发现了不少于六只贵重的金表。三只在他的马甲各个口袋里，一只在他的车票口袋里。由于所有六只都是美国制造的，且在英国很少见，因此这被认为不是他的赃物。其中三只表有罗切斯特制表公司的标记，而那只小巧的、镶满宝石并装饰华丽的则来自纽约的蒂芙尼。他口袋里的其他物品包括一把由谢菲尔德的罗杰斯制造的带螺旋刀的象牙刀、一面直径一英寸的小圆镜、一张去莱斯特剧院的重新入场券、一只装满火柴的银盒以及一个装有两根雪茄的棕色皮革雪茄盒，还有两英镑十四先令的现金。显然，无论导致他死亡的动机是什么，抢劫都不是其中之一。如前所述，这名男子的内衣上没有任何标记，似乎是新的，他的外套上没有裁缝的名字。在外貌上，他年轻、矮小、面颊光滑，五官精致，他的前牙中有一颗。有关的两个车厢被解耦并侧轨。然后，在苏格兰场的范探长和铁路公司侦探亨德森先生到达后，对所有情况进行了详尽的调查。已确定确实发生了犯罪。子弹似乎来自小手枪或左轮手枪，且是从一定距离发射的，因为没有衣物烧焦的痕迹，车厢里没有找到武器，这最终否定了自杀的理论，也没有发现列车员看到的高个绅士手中的棕色皮包。在威尔斯登和拉格比之间不间断行驶的过程中，不可能有一个人下车而另一个人上车。列车员约翰·帕尔默在审讯时能够提供一些证据，为这个事件带来了一些线索。根据他的说法，在特灵和切丁顿之间，有一个地方，由于线路维修，火车的速度在几分钟内减慢到不超过每小时八到十英里。在那个地方，一个人，甚至是一个特别灵活的女人，可能会在没有严重受伤的情况下下车。确实有一群铺轨工人在那里，他们什么也没看到，但他们通常站在轨道中间，而打开的车厢门则在远侧，因此可以想象，在黑暗逐渐降临时，有人可能在无人注意的情况下下车，陡峭的坡道瞬间遮挡了任何跳下车的人，使其不被工人看到。在威尔斯登和拉格比之间的线路仔细检查中，发现了一件可能与特灵附近的悲剧有关的发现：在火车减速的地方的坡底，发现了一本小口袋新约，十分破旧。它是由伦敦的圣经协会印刷的，封面上写着“约翰寄给爱丽丝”。在扉页上，下面写着詹姆斯、1859年，以及在其下方，爱德华、1869年11月1日，所有的条目均用相同的笔迹书写。这是唯一的线索，如果可以称之为线索的话，足够坚实，可以作为有利调查的基础。然而，如果认为这很有帮助，那就是错误的。相反，英美两国的媒体充斥着各种建议和猜测，其中大多数显然是荒谬的。发现这些手表是美国制造的，以及与他前牙的金齿有关的一些特殊之处似乎表明死者是美国公民，尽管他的内衣和靴子无疑是英国制造的。一些人猜测他可能藏在座位下，被发现后由于某种原因，可能是因为他偷听到了他们的罪行秘密，被同伴杀死。结合对无政府主义和其他秘密社团的凶残和狡猾的普遍论述，这一理论听起来和其他任何理论一样可信。事实上，他没有票的情况也是一致的。',\n",
       " 4227)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"Coming as it did at a period of exceptional dullness. It attracted perhaps rather more attention than it deserved, but it offered to the public that mixture of the whimsical and the tragic which is most stimulating to the popular imagination. Interest drooped, however, when, after weeks of fruitless investigation, it was found that no final explanation of the facts was forthcoming and the tragedy seemed from that time. It would be as well, perhaps, that i should refresh their memories as to the singular facts upon which this commentary is founded. These facts were briefly as follows: at five o'clock on the evening of the eighteenth of march, In the year already mentioned, a train left euston station for manchester. It was a rainy, squally day which grew wilder as it progressed, so it was by no means the weather in which anyone would travel who was not driven to do so by necessity. The train, however, is a favourite one among manchester business men who are returning from town, for it does the journey in four hours and twenty minutes, with only three stoppages upon the way. In spite of the inclement evening, it was therefore fairly well filled. Upon the occasion of which i speak, the guard of the train was a tried servant of the company, a man who had worked for twenty two years without a blemish or complaint. His name was john palmer. The station clock was upon the stroke of five and the guard was about to give the customary signal to the engine driver when he observed two belated passengers hurrying down the platform. The one was An exceptionally tall man dressed in a long black overcoat with astrakhan collar and cuffs. I have already said that the evening was an inclement one and the tall traveller had the high, warm collar. Turned up to protect his throat against the bitter march wind. He appeared, as far as the guard could judge by so hurried an inspection, to be a man between fifty and sixty years of age. Which outpaced the gentleman beside her. She wore a long fawn coloured dust cloak, a black close fitting toque and a dark veil which concealed the greater part of her face. The two might very well have passed as father and daughter. They walked swiftly down the line of carriages, glancing in at the windows, until the guard, john palmer, overtook them. Now then, sir, look sharp, the train is going, said he. First class the man answered. The guard turned the handle of the nearest door in the carriage which he had opened, there sat a small man with a cigar in his mouth. His appearance seems to have impressed itself upon the guard's memory, for he was prepared afterwards. To describe or to identify him. He was a man of thirty four or thirty five years of age, dressed in some grey material, sharp nosed, alert, with a ruddy weather, beaten face and a small. He glanced up as the door was opened. The tall man paused with his foot upon the step. This is a smoking compartment. The lady dislikes smoke. All right, here you are, sir, said john palmer. He slammed the door of the smoking carriage, opened that of the next one which was empty, and thrust the two travellers in. At the same moment he sounded his whistle. And the wheels of the train began to move. The man with the cigar was at the window of his carriage and said something to the guard as he rolled past him, but the words were lost in the bustle of the departure. Palmer stepped into the guard's van. As it came up to him and thought no more of the incident. Twelve minutes after its departure, the train reached willesden junction, where it stopped for a very short interval. An examination of the tickets has made it certain. That no one either joined or left it at this time and no passenger was seen to alight upon the platform. At five fourteen the journey to manchester was resumed and rugby was reached at six fifty. The express being five minutes late at rugby, the attention of the station officials was drawn to the fact that the door of one of the first class carriages was open. An examination of that compartment and of its neighbour. Disclosed a remarkable state of affairs: the smoking carriage in which the short red faced man. Save for a half smoked cigar, there was no trace whatever of its recent occupant. The door of this carriage was fastened in the next compartment, to which attention had been originally drawn. There was no sign either of the gentleman with the astrakhan collar or of the young lady who accompanied him. All three passengers had disappeared. On the other hand, there was found upon the floor of this carriage. The one in which the tall traveller and the lady had been a young man, fashionably dressed and of elegant appearance. He lay with his knees. An elbow upon either seat, a bullet had penetrated his heart, and his death must have been instantaneous. No one had seen such a man enter the train, and no railway ticket was found in his pocket. As what had occurred to the three people who had started an hour and a half before from willesden in those two compartments. I have said that there was no personal property which might help to identify him. But it is true that there was one peculiarity about this unknown young man which was much commented upon at the time: in his pockets were found no fewer than six valuable gold watches. Three in the various pockets of his waist coat, one in his ticket pocket. And that this was his plunder was discounted by the fact that all six were of american make and of a type which is rare in england. Three of them bore the mark of the rochester watchmaking company. And the small one, which was highly jewelled and ornamented, was from tiffany of new york. The other contents of his pocket consisted of an ivory knife with a corkscrew by rodgers of sheffield, a small circular mirror. One inch in diameter, a readmission slip to the lyceum theatre, a silver box full of vesta matches and a brown leather cigar case containing two cheroots. Also two pounds fourteen shillings in money. It was clear then that whatever motives may have led to his death, robbery was not among them. As already mentioned, there were no markings upon the man's linen. Which appeared to be new, and no tailor's name upon his coat. In appearance he was young, short, smooth, cheeked and delicately featured one of his front teeth. The two compartments in question was uncoupled and side tracked. Then, on the arrival of inspector vane of scotland yard and of mister henderson, a detective in the service of the railway company, an exhaustive inquiry. Was made, into all the circumstances, that crime had been committed was certain. The bullet, which appeared to have come from a small pistol or revolver, had been fired from some little distance. As there was no scorching of the clothes, no weapon was found in the compartment which finally disposed of the theory of suicide, nor was there any sign of the brown leather bag which the guard had seen in the hand of the tall gentleman. Could get out of the train and one other get in during the unbroken run between willesden and rugby. John palmer, the guard was able at the inquest to give some evidence which threw a little light upon the matter. There was a spot between tring and cheddington, according to his statement, where, on account of some repairs to the line, The train had, for a few minutes, slowed down to a pace not exceeding eight or ten miles an hour. At that place, it might be possible for a man, or even for an exceptionally active woman, to have left the train without serious injury. It was true that a gang of platelayers was there and that they had seen nothing, but it was their custom to stand in the middle between the metals, and the open carriage door was upon the far side. So that it was conceivable that someone might have alighted unseen as the darkness would by that time be drawing in a steep embankment- would instantly screen anyone who sprang out from the observation of the navvies. A careful examination of the line between willesden and rugby resulted in one discovery which might or might not have a bearing upon the tragedy near tring, at the very place where the train slowed down. There was found at the bottom of the embankment a small pocket testament, very shabby and worn. It was printed by the bible society of london and bore an inscription from john to alice. Upon the fly leaf. Underneath was written james. Eighteen, fifty nine, and beneath that again, edward november first, eighteen sixty nine, all the entries being in the same handwriting. This was the only clue, if it could be called a clue. Which was solid enough to form the basis for a profitable investigation. It would be a mistake, however. On the contrary, the press both in england and in america teemed with suggestions and suppositions, most of which were obviously absurd. The fact that the watches were of american make. And some peculiarities in connection with the gold stopping of his front tooth appeared to indicate that the deceased was a citizen of the united states, though his linen clothes and boots were undoubtedly of british manufacture. It was surmised by some that he was concealed under the seat and that, being discovered he was for some reason, possibly because he had overheard their guilty secrets put to death by his fellow passengers. When coupled with generalities as to the ferocity and cunning of anarchical and other secret societies, this theory sounded as plausible as any. The fact that he should be without a ticket would be consistent.\"\n",
    "openai_translate_one('zh-CN', example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2de610e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../datasets/LongSpeech/all_audios.jsonl\")\n",
    "OUTPUT_PATH = Path(\"../datasets/LongSpeechQA/translation.jsonl\")\n",
    "BATCH_SIZE = 100  \n",
    "CONCURRENCY_LIMIT = 500\n",
    "semaphore = asyncio.Semaphore(CONCURRENCY_LIMIT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7b58eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_from_file(path, max_lines=-1):\n",
    "    if not (path.exists() and path.is_file()):\n",
    "        print(f\"⚠️ 警告: 文件不存在或路径不是一个文件 - {path}\")\n",
    "\n",
    "    try:\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            lines_to_process = f  \n",
    "            if max_lines != -1:\n",
    "                lines_to_process = itertools.islice(f, max_lines)\n",
    "            \n",
    "            yield from lines_to_process\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"读取文件 '{path}' 时发生错误: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09eface8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iterator(iterator, batch_size):\n",
    "    while True:\n",
    "        batch = list(islice(iterator, batch_size))\n",
    "        if not batch:\n",
    "            return\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fed7aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_openai_translate_one(client, target_lang, content, original_record_info):\n",
    "\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt.get(target_lang, f\"Translate to {target_lang}\")},\n",
    "                {\"role\": \"user\", \"content\": \"###\" + content + \"###\"},\n",
    "            ]\n",
    "\n",
    "\n",
    "            completion = await client.chat.completions.create(\n",
    "                model=model_name,      \n",
    "                messages=messages,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9\n",
    "            )\n",
    "            \n",
    "\n",
    "            translated = completion.choices[0].message.content.replace(\"#\", \"\")\n",
    "            tokens_used = completion.usage.total_tokens\n",
    "            \n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"original_info\": original_record_info,\n",
    "                \"target_lang\": target_lang,\n",
    "                \"translated_text\": translated,\n",
    "                \"tokens_used\": tokens_used\n",
    "            }\n",
    "        except Exception as e:\n",
    "\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"original_info\": original_record_info,\n",
    "                \"target_lang\": target_lang,\n",
    "                \"error\": e\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aaadc80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def batch_processing():\n",
    "    total_tokens_used = 0\n",
    "    total_lines_processed = 0\n",
    "    \n",
    "    total_lines = 8411\n",
    "\n",
    "    async_client = AsyncOpenAI(\n",
    "        api_key='aib_machinetranslation_a6a051',\n",
    "        base_url= \"https://pre-openai-keys.alibaba-inc.com\"\n",
    "    )\n",
    "\n",
    "    data_iter = stream_from_file(DATA_PATH, -1)\n",
    "    filtered_iter = (line for line in data_iter if (\"librispeech\" in line or \"tedlium\" in line))\n",
    "\n",
    "    async with aiofiles.open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        with tqdm(total=total_lines, desc=\"Translating Batches\") as progress_bar:\n",
    "            for batch in batch_iterator(filtered_iter, BATCH_SIZE):\n",
    "                tasks = []\n",
    "                for line in batch:\n",
    "                    try:\n",
    "                        ljs = json.loads(line.strip())\n",
    "                        source_lang = ljs.get('language')\n",
    "                        content = ljs.get('transcribe')\n",
    "                        wav_id = ljs.get('id')\n",
    "\n",
    "                        if not all([source_lang, content, wav_id]): continue\n",
    "                        \n",
    "                        original_record_info = {\n",
    "                            \"source_lang\": source_lang,\n",
    "                            \"wav_path\": str(Path(DATA_PATH.parent / 'wavs' / (wav_id + '.wav')).resolve())\n",
    "                        }\n",
    "                        \n",
    "                        target_langs = random.sample([lang for lang in possible_langs if lang != source_lang], 5)\n",
    "                        \n",
    "                        for target_lang in target_langs:\n",
    "                            \n",
    "                            task = async_openai_translate_one(async_client, target_lang, content, original_record_info)\n",
    "                            tasks.append(task)\n",
    "                    except (json.JSONDecodeError, AttributeError):\n",
    "                        continue\n",
    "\n",
    "                if not tasks: continue\n",
    "                \n",
    "                results = await asyncio.gather(*tasks)\n",
    "\n",
    "                for result in results:\n",
    "                    if result[\"status\"] == \"success\":\n",
    "                        total_tokens_used += result[\"tokens_used\"]\n",
    "                        \n",
    "                        record = {\n",
    "                            \"source_lang\": result[\"original_info\"][\"source_lang\"],\n",
    "                            \"target_lang\": result[\"target_lang\"],\n",
    "                            \"content\": result[\"translated_text\"],\n",
    "                            \"wav_path\": result[\"original_info\"][\"wav_path\"]\n",
    "                        }\n",
    "                        await outfile.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
    "                    else:\n",
    "                        print(f\"A task failed for {result['original_info']} -> {result['target_lang']}: {result['error']}\")\n",
    "\n",
    "                progress_bar.update(len(batch))\n",
    "                progress_bar.set_postfix({\"total_tokens\": f\"{total_tokens_used:,}\", \"concurrency\": CONCURRENCY_LIMIT})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc2929f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating Batches:  50%|████▉     | 4200/8411 [1:35:55<2:14:12,  1.91s/it, total_tokens=105,161,685, concurrency=500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A task failed for {'source_lang': 'en', 'wav_path': '/mnt/workspace/renyi/datasets/LongSpeech/wavs/004133.wav'} -> zh-CN: Connection error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating Batches:  80%|███████▉  | 6700/8411 [2:28:28<33:48,  1.19s/it, total_tokens=162,041,532, concurrency=500]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A task failed for {'source_lang': 'en', 'wav_path': '/mnt/workspace/renyi/datasets/LongSpeech/wavs/006642.wav'} -> hu: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating Batches:  81%|████████  | 6800/8411 [2:30:43<33:08,  1.23s/it, total_tokens=164,232,555, concurrency=500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A task failed for {'source_lang': 'en', 'wav_path': '/mnt/workspace/renyi/datasets/LongSpeech/wavs/006755.wav'} -> vi: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating Batches:  88%|████████▊ | 7400/8411 [2:42:29<22:12,  1.32s/it, total_tokens=176,286,358, concurrency=500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A task failed for {'source_lang': 'en', 'wav_path': '/mnt/workspace/renyi/datasets/LongSpeech/wavs/007303.wav'} -> vi: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating Batches: 100%|██████████| 8411/8411 [3:06:33<00:00,  1.33s/it, total_tokens=197,096,990, concurrency=500]\n"
     ]
    }
   ],
   "source": [
    "await batch_processing()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7c56b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42051"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amount = 0\n",
    "with open(OUTPUT_PATH, \"r\", encoding=\"utf-8\") as outfile:\n",
    "    for line in outfile:\n",
    "        amount +=1\n",
    "\n",
    "amount\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d4d6381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating Records:   0%|          | 8/8411 [26:07<457:23:28, 195.95s/it, total_tokens=202,826]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 41\u001b[0m\n\u001b[1;32m     37\u001b[0m target_langs \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msample(sampled_lang, \u001b[39m5\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[39mfor\u001b[39;00m target_lang \u001b[39min\u001b[39;00m target_langs:\n\u001b[0;32m---> 41\u001b[0m     translated, tokens_used \u001b[39m=\u001b[39m openai_translate_one(target_lang, content)\n\u001b[1;32m     43\u001b[0m     total_tokens_used \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tokens_used\n\u001b[1;32m     45\u001b[0m     record \u001b[39m=\u001b[39m {\n\u001b[1;32m     46\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msource_lang\u001b[39m\u001b[39m\"\u001b[39m: source_lang,\n\u001b[1;32m     47\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtarget_lang\u001b[39m\u001b[39m\"\u001b[39m: target_lang,\n\u001b[1;32m     48\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: translated,\n\u001b[1;32m     49\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwav_path\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mstr\u001b[39m(wav_path)\n\u001b[1;32m     50\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m, in \u001b[0;36mopenai_translate_one\u001b[0;34m(lang, content)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mopenai_translate_one\u001b[39m(lang, content):\n\u001b[0;32m----> 2\u001b[0m     completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mchat\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m         model\u001b[39m=\u001b[39;49mmodel_name,\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m         messages\u001b[39m=\u001b[39;49m[\n\u001b[1;32m      7\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: system_prompt[lang]},\n\u001b[1;32m      8\u001b[0m         {\n\u001b[1;32m      9\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39m###\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m  content \u001b[39m+\u001b[39;49m  \u001b[39m\"\u001b[39;49m\u001b[39m###\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     11\u001b[0m         },\n\u001b[1;32m     12\u001b[0m         ],\n\u001b[1;32m     13\u001b[0m         \u001b[39m#max_tokens=100,\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m         temperature\u001b[39m=\u001b[39;49m\u001b[39m0.7\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m         top_p\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m,\n\u001b[1;32m     16\u001b[0m         frequency_penalty\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,\n\u001b[1;32m     17\u001b[0m         presence_penalty\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,\n\u001b[1;32m     18\u001b[0m         n\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[1;32m     19\u001b[0m     )\n\u001b[1;32m     20\u001b[0m     \u001b[39mif\u001b[39;00m validate_openai_translation(completion, lang, \u001b[39m100\u001b[39m):\n\u001b[1;32m     21\u001b[0m         \u001b[39mreturn\u001b[39;00m completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m), completion\u001b[39m.\u001b[39musage\u001b[39m.\u001b[39mtotal_tokens\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/openai/_utils/_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 287\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:1087\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   1045\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcreate\u001b[39m(\n\u001b[1;32m   1046\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1084\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m   1085\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m   1086\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m-> 1087\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m   1088\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1089\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[1;32m   1090\u001b[0m             {\n\u001b[1;32m   1091\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[1;32m   1092\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[1;32m   1093\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39maudio\u001b[39;49m\u001b[39m\"\u001b[39;49m: audio,\n\u001b[1;32m   1094\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[1;32m   1095\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[1;32m   1096\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[1;32m   1097\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[1;32m   1098\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: logprobs,\n\u001b[1;32m   1099\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_completion_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_completion_tokens,\n\u001b[1;32m   1100\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[1;32m   1101\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m: metadata,\n\u001b[1;32m   1102\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodalities\u001b[39;49m\u001b[39m\"\u001b[39;49m: modalities,\n\u001b[1;32m   1103\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[1;32m   1104\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mparallel_tool_calls\u001b[39;49m\u001b[39m\"\u001b[39;49m: parallel_tool_calls,\n\u001b[1;32m   1105\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mprediction\u001b[39;49m\u001b[39m\"\u001b[39;49m: prediction,\n\u001b[1;32m   1106\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[1;32m   1107\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mreasoning_effort\u001b[39;49m\u001b[39m\"\u001b[39;49m: reasoning_effort,\n\u001b[1;32m   1108\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[1;32m   1109\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[1;32m   1110\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mservice_tier\u001b[39;49m\u001b[39m\"\u001b[39;49m: service_tier,\n\u001b[1;32m   1111\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[1;32m   1112\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstore\u001b[39;49m\u001b[39m\"\u001b[39;49m: store,\n\u001b[1;32m   1113\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[1;32m   1114\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream_options\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream_options,\n\u001b[1;32m   1115\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[1;32m   1116\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtool_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m: tool_choice,\n\u001b[1;32m   1117\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtools\u001b[39;49m\u001b[39m\"\u001b[39;49m: tools,\n\u001b[1;32m   1118\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_logprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_logprobs,\n\u001b[1;32m   1119\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[1;32m   1120\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[1;32m   1121\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mweb_search_options\u001b[39;49m\u001b[39m\"\u001b[39;49m: web_search_options,\n\u001b[1;32m   1122\u001b[0m             },\n\u001b[1;32m   1123\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParamsStreaming\n\u001b[1;32m   1124\u001b[0m             \u001b[39mif\u001b[39;49;00m stream\n\u001b[1;32m   1125\u001b[0m             \u001b[39melse\u001b[39;49;00m completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParamsNonStreaming,\n\u001b[1;32m   1126\u001b[0m         ),\n\u001b[1;32m   1127\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m   1128\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m   1129\u001b[0m         ),\n\u001b[1;32m   1130\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[1;32m   1131\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1132\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[1;32m   1133\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/openai/_base_client.py:1256\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mpost\u001b[39m(\n\u001b[1;32m   1243\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1244\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1251\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1252\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1253\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1254\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1255\u001b[0m     )\n\u001b[0;32m-> 1256\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/openai/_base_client.py:979\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    977\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 979\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49msend(\n\u001b[1;32m    980\u001b[0m         request,\n\u001b[1;32m    981\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_should_stream_response_body(request\u001b[39m=\u001b[39;49mrequest),\n\u001b[1;32m    982\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    983\u001b[0m     )\n\u001b[1;32m    984\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    985\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mEncountered httpx.TimeoutException\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[1;32m    915\u001b[0m     request,\n\u001b[1;32m    916\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[1;32m    917\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    918\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[1;32m    919\u001b[0m )\n\u001b[1;32m    920\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[1;32m    943\u001b[0m         request,\n\u001b[1;32m    944\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[1;32m    945\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[1;32m    946\u001b[0m     )\n\u001b[1;32m    947\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mrequest\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[1;32m    980\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[1;32m   1016\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[39m.\u001b[39mrequest \u001b[39m=\u001b[39m request\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[1;32m    252\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[39m=\u001b[39mResponseStream(resp\u001b[39m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[39m=\u001b[39mresp\u001b[39m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[39mraise\u001b[39;00m exc \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[39m=\u001b[39m pool_request\u001b[39m.\u001b[39mwait_for_connection(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[39m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(\n\u001b[1;32m    237\u001b[0m         pool_request\u001b[39m.\u001b[39;49mrequest\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    239\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[39m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[39m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[39m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[39m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connect_failed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mhandle_request(request)\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[39mwith\u001b[39;00m Trace(\u001b[39m\"\u001b[39m\u001b[39mresponse_closed\u001b[39m\u001b[39m\"\u001b[39m, logger, request) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mreceive_response_headers\u001b[39m\u001b[39m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[39mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_response_headers(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    107\u001b[0m     trace\u001b[39m.\u001b[39mreturn_value \u001b[39m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[39m=\u001b[39m timeouts\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_event(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    178\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(event, h11\u001b[39m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[39mif\u001b[39;00m event \u001b[39mis\u001b[39;00m h11\u001b[39m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network_stream\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    218\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mREAD_NUM_BYTES, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    219\u001b[0m     )\n\u001b[1;32m    221\u001b[0m     \u001b[39m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[39m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[39m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[39m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mtheir_state \u001b[39m==\u001b[39m h11\u001b[39m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv(max_bytes)\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1289\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1290\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1291\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1292\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(buflen)\n\u001b[1;32m   1293\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m, buffer)\n\u001b[1;32m   1164\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m)\n\u001b[1;32m   1166\u001b[0m \u001b[39mexcept\u001b[39;00m SSLError \u001b[39mas\u001b[39;00m x:\n\u001b[1;32m   1167\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m SSL_ERROR_EOF \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "total_tokens_used = 0 \n",
    "\n",
    "try:\n",
    "    with open(DATA_PATH, 'r', encoding='utf-8') as f:\n",
    "        total_lines = sum(1 for _ in f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Input file not found at {DATA_PATH}\")\n",
    "    total_lines = 0\n",
    "\n",
    "test_lines = 10\n",
    "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    data_iter = stream_from_file(DATA_PATH, -1)\n",
    "    filtered_iter = (line for line in data_iter if (\"librispeech\" in line or \"tedlium\" in line))\n",
    "    progress_bar = tqdm(filtered_iter, total=8411, desc=\"Translating Records\")\n",
    "\n",
    "    for line in progress_bar:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            ljs = json.loads(line)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "            \n",
    "        source_lang = ljs.get('language')\n",
    "        content = ljs.get('transcribe')\n",
    "        wav_id = ljs.get('id')\n",
    "\n",
    "        if not all([source_lang, content, wav_id]):\n",
    "            continue\n",
    "\n",
    "        wav_path = Path(DATA_PATH.parent / 'wavs' / (wav_id + '.wav')).resolve()\n",
    "        \n",
    "        sampled_lang = [x for x in possible_langs if x != source_lang]\n",
    "    \n",
    "        target_langs = random.sample(sampled_lang, 5)\n",
    "\n",
    "        for target_lang in target_langs:\n",
    "\n",
    "            translated, tokens_used = openai_translate_one(target_lang, content)\n",
    "            \n",
    "            total_tokens_used += tokens_used\n",
    "            \n",
    "            record = {\n",
    "                \"source_lang\": source_lang,\n",
    "                \"target_lang\": target_lang,\n",
    "                \"content\": translated,\n",
    "                \"wav_path\": str(wav_path)\n",
    "            }\n",
    "            outfile.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
    "            progress_bar.set_postfix({\"total_tokens\": f\"{total_tokens_used:,}\"})\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
