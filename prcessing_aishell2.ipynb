{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T09:11:55.586227Z",
     "start_time": "2025-07-17T09:11:55.580595Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cuda:0\n",
      "/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"none\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from lhotse import CutSet\n",
    "from mylhotse.aishell2 import prepare_aishell2\n",
    "import logging\n",
    "from util import *\n",
    "import numpy as np\n",
    "import faiss, gc\n",
    "from lhotse_util import from_strategy_to_cuts\n",
    "from lhotse.cut import append_cuts\n",
    "import librosa\n",
    "from bitarray import bitarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3a1954a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T09:11:55.613462Z",
     "start_time": "2025-07-17T09:11:55.610638Z"
    }
   },
   "outputs": [],
   "source": [
    "# directory paths to save audio and transcript files\n",
    "IN_DIR = \"../datasets/LongSpeechSource/iOS\"\n",
    "# IN_DIR = \"/mnt/d/voicedata/CommenVoice/delta\"\n",
    "# directory paths to save metadata and processed aduio files\n",
    "OUT_DIR = '../datasets/LongSpeech_p2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "config_setup",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T09:11:55.649710Z",
     "start_time": "2025-07-17T09:11:55.627270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16124\n"
     ]
    }
   ],
   "source": [
    "config = json.load(open(os.path.join(OUT_DIR, 'metadata.json')))\n",
    "AVG_DURATION = config['avg_duration']\n",
    "SAMPLE_RATE = config['sample_rate']\n",
    "OUT_FILE_NAME = config['source']\n",
    "prev_amount = config['amount']\n",
    "print(prev_amount)\n",
    "task = \"asr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de79901c45e3eb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T09:11:59.932123Z",
     "start_time": "2025-07-17T09:11:55.685940Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process aishell2 audio, it takes about 55  minutes using 40 cpu jobs.:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "manifests = prepare_aishell2(corpus_dir=IN_DIR, output_dir=OUT_DIR, num_jobs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c323343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cuts = CutSet()\n",
    "for part in manifests.keys():\n",
    "    rs = manifests[part]['validated']['recordings']\n",
    "    ss = manifests[part]['validated']['supervisions']\n",
    "    cut = CutSet.from_manifests(recordings=rs, supervisions=ss)\n",
    "    cuts += cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccdae1870680c1ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T09:11:59.951408Z",
     "start_time": "2025-07-17T09:11:59.946709Z"
    }
   },
   "outputs": [],
   "source": [
    "resampled_cuts = cuts.to_eager()\n",
    "resampled_cuts.to_jsonl(os.path.join(OUT_DIR, \"commonvoice_raw_cuts.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f8b3bcc268d9c30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T09:12:00.014110Z",
     "start_time": "2025-07-17T09:11:59.964382Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_feature(cuts: CutSet, batch_size: int = 100, dim: int = 384):\n",
    "    cut_list = cuts.to_eager()\n",
    "    n = len(cut_list)\n",
    "\n",
    "    vec_mm = np.memmap(f\"{OUT_DIR}/vecs.f32\", dtype=\"float32\", mode=\"w+\", shape=(n, dim))\n",
    "    dur_mm = np.memmap(f\"{OUT_DIR}/durs.f32\", dtype=\"float32\", mode=\"w+\", shape=(n,))\n",
    "\n",
    "    string_ids = []\n",
    "\n",
    "    ptr = 0\n",
    "    for i in tqdm(range(0, n, batch_size), desc=\"Get Embedding\"):\n",
    "        cut_batch = cut_list[i:i+batch_size]\n",
    "\n",
    "        texts = [c.supervisions[0].text if c.supervisions else \"\" for c in cut_batch]\n",
    "        durations = [c.duration for c in cut_batch]\n",
    "        string_ids.extend([c.id for c in cut_batch])\n",
    "\n",
    "        vec_np = get_sentence_embeddings(texts).astype(\"float32\")\n",
    "        B = len(cut_batch)\n",
    "\n",
    "        vec_mm[ptr:ptr+B] = vec_np\n",
    "        dur_mm[ptr:ptr+B] = durations\n",
    "        ptr += B\n",
    "\n",
    "    vec_mm.flush(); dur_mm.flush()\n",
    "\n",
    "    return vec_mm, dur_mm, string_ids\n",
    "\n",
    "def build_hnsw_index(vec_mm: np.memmap,\n",
    "                     dim: int = 384,\n",
    "                     m: int = 32,\n",
    "                     ef_c: int = 200,\n",
    "                     n_threads: int = mp.cpu_count(),\n",
    "                     out_path: str = \"cache_hnsw.faiss\"):\n",
    "\n",
    "    faiss.omp_set_num_threads(n_threads)\n",
    "    faiss.normalize_L2(vec_mm)\n",
    "\n",
    "    index = faiss.IndexHNSWFlat(dim, m)\n",
    "    index.hnsw.efConstruction = ef_c\n",
    "    index.metric_type = faiss.METRIC_INNER_PRODUCT\n",
    "\n",
    "    index.add(vec_mm)\n",
    "    faiss.write_index(index, os.path.join(OUT_DIR,out_path))\n",
    "    return os.path.join(OUT_DIR,out_path)\n",
    "\n",
    "def get_speaker_embedding_ids(ids, neighs, cuts):\n",
    "    \"\"\"\n",
    "    获取邻居的说话人ID\n",
    "    Returns:\n",
    "        speaker_embeddings: (batch_num, feature_dim)\n",
    "    \"\"\"\n",
    "    speaker_embeddings = []\n",
    "    for idx in neighs:\n",
    "        if idx == -1:\n",
    "            break\n",
    "        real_id = ids[idx]\n",
    "        cut_pth = cuts[real_id].recording.sources[0].source\n",
    "        audio, sr = librosa.load(cut_pth)\n",
    "        speaker_embeddings.append(get_speaker_embedding(audio, sr).flatten())\n",
    "\n",
    "    spk_emb_np = np.array(speaker_embeddings)\n",
    "    pc1 = PCA(n_components=1, svd_solver=\"auto\").fit_transform(spk_emb_np).ravel()\n",
    "    return np.argsort(pc1)\n",
    "\n",
    "def greedy_cluster(index_path: str,\n",
    "                   vec_mm: np.memmap,\n",
    "                   dur_mm: np.memmap,\n",
    "                   ids,\n",
    "                   cuts,\n",
    "                   bucket_min: int = 480,\n",
    "                   bucket_avg: int = 600,\n",
    "                   k_neigh: int = 256,\n",
    "                   ef_s: int = 96):\n",
    "    index = faiss.read_index(index_path)\n",
    "\n",
    "    params = faiss.SearchParametersHNSW()\n",
    "    params.efSearch = ef_s\n",
    "\n",
    "    N = len(vec_mm)\n",
    "    assigned = bitarray(N)\n",
    "    assigned.setall(False)\n",
    "\n",
    "    order = np.argsort(-dur_mm)\n",
    "    buckets = []\n",
    "\n",
    "    for seed in tqdm(order, desc=\"Clustering (Optimized)\"):\n",
    "        if assigned[seed]:\n",
    "            continue\n",
    "\n",
    "        cluster = []\n",
    "        total_dur = 0\n",
    "\n",
    "        unassigned_indices_list = assigned.search(bitarray('0'))\n",
    "        unassigned_indices = np.fromiter(unassigned_indices_list, dtype=np.int64)\n",
    "\n",
    "\n",
    "        if len(unassigned_indices) > 0:\n",
    "            selector = faiss.IDSelectorArray(unassigned_indices)\n",
    "            params.sel = selector\n",
    "\n",
    "            _, neighs = index.search(vec_mm[seed : seed + 1], k_neigh, params=params)\n",
    "\n",
    "            #speaker_order = get_speaker_embedding_ids(ids, neighs[0].tolist(), cuts)\n",
    "            #print(speaker_order)\n",
    "\n",
    "            for idx in neighs[0]:\n",
    "                if idx == -1:\n",
    "                    break\n",
    "                if assigned[idx]:\n",
    "                    print(\"Warning: Already assigned index\", idx)\n",
    "                    continue\n",
    "\n",
    "                cluster.append(int(idx))\n",
    "                assigned[idx] = True\n",
    "                total_dur += dur_mm[idx]\n",
    "                if total_dur >= bucket_avg:\n",
    "                    break\n",
    "\n",
    "            if total_dur < bucket_min:\n",
    "                for i in cluster:\n",
    "                    assigned[i] = False\n",
    "            else:\n",
    "                total_dur = dur_mm[cluster].sum()\n",
    "                buckets.append((cluster, total_dur))\n",
    "\n",
    "    final_buckets = [b for b in buckets if b[1] >= bucket_min]\n",
    "    final_clusters = [c for c, _ in final_buckets]\n",
    "    final_duration = sum(sec for _, sec in final_buckets)\n",
    "\n",
    "    loss = 1 - final_duration / dur_mm.sum()\n",
    "    print(f\"桶数 {len(final_clusters)}, 最终时长 {final_duration:.2f}s, 总时长 {dur_mm.sum():.2f}s, 丢弃比例 {loss:.2%}\")\n",
    "\n",
    "    strategy = []\n",
    "    for cluster in final_clusters:\n",
    "        strategy.append([ids[i] for i in cluster])\n",
    "\n",
    "    return strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98e124a17f4c3bba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T09:12:00.042899Z",
     "start_time": "2025-07-17T09:12:00.028701Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "mock_strategy = [\n",
    "    [\"common_voice_en_43199993-0\", \"common_voice_en_42736613-1\", \"common_voice_en_42798328-2\"],\n",
    "    [\"common_voice_en_43204215-3\", \"common_voice_en_42706055-4\", \"common_voice_en_43139615-5\"]\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "vec_mm, dur_mm, string_ids = build_feature(resampled_cuts)\n",
    "index_path = build_hnsw_index(vec_mm)\n",
    "real_strategy = greedy_cluster(index_path, vec_mm, dur_mm, string_ids, resampled_cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a25e121040a3ae99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T09:12:02.798363Z",
     "start_time": "2025-07-17T09:12:00.059727Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get Embedding: 100%|██████████| 18557/18557 [06:38<00:00, 46.54it/s]\n",
      "Clustering (Optimized): 100%|██████████| 1855619/1855619 [6:20:14<00:00, 81.33it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "桶数 14783, 最终时长 8826442.81s, 总时长 9507185.00s, 丢弃比例 7.16%\n"
     ]
    }
   ],
   "source": [
    "def map_newid_cutset(cutset: CutSet, start_id: int = 0) -> CutSet:\n",
    "    \"\"\"\n",
    "    Map the ids of a CutSet to a new id starting from start_id.\n",
    "    \"\"\"\n",
    "    new_cuts = []\n",
    "    for i, cut in enumerate(cutset):\n",
    "        new_cut = cut.with_id(f\"{start_id + i:06d}\")\n",
    "        new_cuts.append(new_cut)\n",
    "    return CutSet.from_cuts(new_cuts), start_id + len(new_cuts)\n",
    "\n",
    "def build_grouped_cuts(\n",
    "        source_cuts: CutSet,\n",
    "        strategy,\n",
    "        start_id: int = 0\n",
    "    ):\n",
    "\n",
    "    src = {c.id: c for c in source_cuts}\n",
    "\n",
    "    grouped = []\n",
    "    next_id = start_id\n",
    "    for cluster_ids in strategy:\n",
    "        cuts = [src[cid].resample(SAMPLE_RATE) for cid in cluster_ids]\n",
    "        merged = append_cuts(cuts).with_id(f\"{next_id:06d}\")\n",
    "        grouped.append(merged)\n",
    "        next_id += 1\n",
    "\n",
    "    return CutSet.from_cuts(grouped), next_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86e2d3ce5edad1ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T09:12:02.827904Z",
     "start_time": "2025-07-17T09:12:02.823147Z"
    }
   },
   "outputs": [],
   "source": [
    "#grouped_cuts = from_strategy_to_cuts(resampled_cuts.to_eager(), real_strategy)\n",
    "#grouped_cuts , new_amount = map_newid_cutset(grouped_cuts, start_id=prev_amount)\n",
    "\n",
    "grouped_cuts, new_amount = build_grouped_cuts(resampled_cuts, real_strategy, start_id=prev_amount)\n",
    "grouped_cuts.to_jsonl(os.path.join(OUT_DIR, \"grouped_raw_cuts.jsonl\"))\n",
    "print(new_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93d35bb307c93c85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T09:12:02.887233Z",
     "start_time": "2025-07-17T09:12:02.848738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16071\n"
     ]
    }
   ],
   "source": [
    "def json_from_commonvoice_to_allaudios(one_cut, lang = \"en\"):\n",
    "    \"\"\"\n",
    "    Convert a single Commonvoice json record to a list of LongSpeech metadata.\n",
    "    \"\"\"\n",
    "    sources = []\n",
    "    speakers = set()\n",
    "    total_dur = 0\n",
    "    transcripts = []\n",
    "    slices = []\n",
    "\n",
    "    for subcut in one_cut[\"tracks\"]:\n",
    "        total_dur += subcut[\"cut\"][\"duration\"]\n",
    "        full_pth = subcut[\"cut\"][\"recording\"][\"sources\"][0][\"source\"]\n",
    "        slices.append([subcut[\"cut\"][\"start\"], subcut[\"cut\"][\"duration\"]])\n",
    "        sources.append(full_pth.split(\"clips\")[-1])\n",
    "        [speakers.add(s[\"speaker\"]) for s in subcut[\"cut\"][\"supervisions\"] if s[\"speaker\"]]\n",
    "        transcript_param = \" \".join([s[\"text\"] for s in subcut[\"cut\"][\"supervisions\"] if s[\"text\"]])\n",
    "        if transcript_param != \"\":\n",
    "            transcripts.append(transcript_param)\n",
    "        else:\n",
    "            print(subcut)\n",
    "\n",
    "    return {\n",
    "        \"id\": one_cut[\"id\"],\n",
    "        \"source_ds\": \"CommonVoice\",\n",
    "        \"duration_sec\": total_dur,\n",
    "        \"audio_auto\": False,\n",
    "        \"text_auto\": False,\n",
    "        \"language\": lang,\n",
    "        \"num_speakers\": len(speakers),\n",
    "        \"num_switches\": len(transcripts),\n",
    "        \"slice\": slices,\n",
    "        \"transcribe\": \" \".join(transcripts),\n",
    "        \"components\": sources,\n",
    "    }\n",
    "\n",
    "\n",
    "def convert_record(source_jsonl_path: str, target_jsonl_path: str, map_fn, lang: str):\n",
    "    with open(source_jsonl_path, \"r\", encoding=\"utf-8\") as src_f, \\\n",
    "         open(target_jsonl_path, \"a\", encoding=\"utf-8\") as tgt_f:\n",
    "        for line in src_f:\n",
    "            item = json.loads(line)\n",
    "            new_item = map_fn(item, lang)\n",
    "            tgt_f.write(json.dumps(new_item, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "419954e0b702973b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T09:12:02.909723Z",
     "start_time": "2025-07-17T09:12:02.903504Z"
    }
   },
   "outputs": [],
   "source": [
    "def _save_one(cut, out_dir):\n",
    "\n",
    "    os.environ[\"LHOTSE_AUDIO_DURATION_MISMATCH_TOLERANCE\"] = \"1.5\"\n",
    "    dst = Path(out_dir) / f\"{cut.id}.wav\"\n",
    "    cut.save_audio(dst, format=\"wav\")\n",
    "    return cut.id\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a899487",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_record(os.path.join(OUT_DIR, \"grouped_raw_cuts.jsonl\"),\n",
    "               os.path.join(OUT_DIR, OUT_FILE_NAME),\n",
    "               json_from_commonvoice_to_allaudios, lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd73da044d6b28be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T09:12:02.980072Z",
     "start_time": "2025-07-17T09:12:02.932469Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m convert_record(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(OUT_DIR, \u001b[39m\"\u001b[39;49m\u001b[39mgrouped_raw_cuts.jsonl\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      2\u001b[0m                os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(OUT_DIR, OUT_FILE_NAME),\n\u001b[1;32m      3\u001b[0m                json_from_commonvoice_to_allaudios, lang)\n",
      "Cell \u001b[0;32mIn[11], line 42\u001b[0m, in \u001b[0;36mconvert_record\u001b[0;34m(source_jsonl_path, target_jsonl_path, map_fn, lang)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(source_jsonl_path, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m src_f, \\\n\u001b[1;32m     40\u001b[0m      \u001b[39mopen\u001b[39m(target_jsonl_path, \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m tgt_f:\n\u001b[1;32m     41\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m src_f:\n\u001b[0;32m---> 42\u001b[0m         item \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(line)\n\u001b[1;32m     43\u001b[0m         new_item \u001b[39m=\u001b[39m map_fn(item, lang)\n\u001b[1;32m     44\u001b[0m         tgt_f\u001b[39m.\u001b[39mwrite(json\u001b[39m.\u001b[39mdumps(new_item, ensure_ascii\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[39mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "from worker import save_one_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23e3f79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_audios_from_cutset(cutset, out_dir, num_jobs=None):\n",
    "    if num_jobs is None:\n",
    "        num_jobs = os.cpu_count()\n",
    "\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    context = mp.get_context(\"spawn\")\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=num_jobs, mp_context=context) as pool:\n",
    "        futures = [\n",
    "            pool.submit(save_one_worker, cut, out_dir) \n",
    "            for cut in tqdm(cutset, desc=\"1. 提交任务中\")\n",
    "        ]\n",
    "        for _ in tqdm(\n",
    "        as_completed(futures),\n",
    "        total=len(futures),\n",
    "        desc=f\"Saving WAVs ({num_jobs} workers)\"\n",
    "        ):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4d0d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"LHOTSE_AUDIO_DURATION_MISMATCH_TOLERANCE\"] =   \"1.5\"\n",
    "mp.set_start_method('spawn', force=True)\n",
    "save_audios_from_cutset(grouped_cuts, os.path.join(OUT_DIR, 'wavs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e11d50148313079e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T09:12:17.324819Z",
     "start_time": "2025-07-17T09:12:02.993532Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1. 提交任务中: 100%|██████████| 14783/14783 [00:00<00:00, 34360.30it/s]\n",
      "Saving WAVs (12 workers):  34%|███▎      | 4977/14783 [4:01:01<5:27:28,  2.00s/it] "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "def with_new_features(cuts: CutSet, batch_size = 100) -> CutSet:\n",
    "    cutset_list = cuts.split_lazy(OUT_DIR, batch_size)\n",
    "    new_cutset_list = []\n",
    "    for i, cutset in enumerate(tqdm(cutset_list, desc=\"Processing cuts\")):\n",
    "        text_list = [cut.supervisions[0].text if cut.supervisions else \"\" for cut in cutset]\n",
    "        id_list = [cut.id for cut in cutset]\n",
    "        duration = [cut.duration for cut in cutset]\n",
    "        semantic_np = get_sentence_embeddings(\n",
    "            text_list\n",
    "        )\n",
    "\n",
    "        updated_cuts = []\n",
    "        for cut, embedding in zip(cutset, semantic_np):\n",
    "            cut = cut.with_custom(\"semantic_emb\", embedding.tolist())  # 如果是 numpy array\n",
    "            updated_cuts.append(cut)\n",
    "\n",
    "\n",
    "        new_cutset_list.append(CutSet.from_cuts(updated_cuts))\n",
    "    merged_cuts = combine(*new_cutset_list)\n",
    "    return merged_cuts\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbe4c66ba1092b59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T09:12:17.347822Z",
     "start_time": "2025-07-17T09:12:17.342351Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 13607/16071 [00:56<00:11, 206.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading ../datasets/LongSpeech_p2/wavs/013562.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013563.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013564.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013565.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013566.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013567.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013568.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013569.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013570.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013571.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013572.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013573.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013574.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013575.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013576.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013577.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013578.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013579.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013580.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013581.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013582.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013583.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013584.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013585.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013586.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013587.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013588.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013589.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013590.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013591.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013592.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013593.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013594.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013595.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013596.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013597.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013598.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013599.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013600.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013601.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013602.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013603.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013604.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013605.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013606.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013607.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013608.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013609.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013610.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013611.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013612.wav: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 13658/16071 [00:56<00:10, 227.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading ../datasets/LongSpeech_p2/wavs/013613.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013614.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013615.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013616.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013617.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013618.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013619.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013620.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013621.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013622.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013623.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013624.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013625.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013626.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013627.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013628.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013629.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013630.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013631.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013632.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013633.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013634.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013635.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013636.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013637.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013638.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013639.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013640.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013641.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013642.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013643.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013644.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013645.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013646.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013647.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013648.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013649.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013650.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013651.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013652.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013653.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013654.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013655.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013656.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013657.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013658.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013659.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013660.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013661.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013662.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013663.wav: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 13682/16071 [00:56<00:11, 214.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading ../datasets/LongSpeech_p2/wavs/013664.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013665.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013666.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013667.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013668.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013669.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013670.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013671.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013672.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013673.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013674.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013675.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013676.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013677.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013678.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013679.wav: fmt chunk and/or data chunk missing\n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013680.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013681.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013682.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013684.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013685.wav: file does not start with RIFF id\n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013686.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013687.wav: fmt chunk and/or data chunk missing\n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013688.wav: \n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013690.wav: file does not start with RIFF id\n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013691.wav: file does not start with RIFF id\n",
      "Error reading ../datasets/LongSpeech_p2/wavs/013692.wav: file does not start with RIFF id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16071/16071 [02:51<00:00, 93.93it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['013562',\n",
       " '013563',\n",
       " '013564',\n",
       " '013565',\n",
       " '013566',\n",
       " '013567',\n",
       " '013568',\n",
       " '013569',\n",
       " '013570',\n",
       " '013571',\n",
       " '013572',\n",
       " '013573',\n",
       " '013574',\n",
       " '013575',\n",
       " '013576',\n",
       " '013577',\n",
       " '013578',\n",
       " '013579',\n",
       " '013580',\n",
       " '013581',\n",
       " '013582',\n",
       " '013583',\n",
       " '013584',\n",
       " '013585',\n",
       " '013586',\n",
       " '013587',\n",
       " '013588',\n",
       " '013589',\n",
       " '013590',\n",
       " '013591',\n",
       " '013592',\n",
       " '013593',\n",
       " '013594',\n",
       " '013595',\n",
       " '013596',\n",
       " '013597',\n",
       " '013598',\n",
       " '013599',\n",
       " '013600',\n",
       " '013601',\n",
       " '013602',\n",
       " '013603',\n",
       " '013604',\n",
       " '013605',\n",
       " '013606',\n",
       " '013607',\n",
       " '013608',\n",
       " '013609',\n",
       " '013610',\n",
       " '013611',\n",
       " '013612',\n",
       " '013613',\n",
       " '013614',\n",
       " '013615',\n",
       " '013616',\n",
       " '013617',\n",
       " '013618',\n",
       " '013619',\n",
       " '013620',\n",
       " '013621',\n",
       " '013622',\n",
       " '013623',\n",
       " '013624',\n",
       " '013625',\n",
       " '013626',\n",
       " '013627',\n",
       " '013628',\n",
       " '013629',\n",
       " '013630',\n",
       " '013631',\n",
       " '013632',\n",
       " '013633',\n",
       " '013634',\n",
       " '013635',\n",
       " '013636',\n",
       " '013637',\n",
       " '013638',\n",
       " '013639',\n",
       " '013640',\n",
       " '013641',\n",
       " '013642',\n",
       " '013643',\n",
       " '013644',\n",
       " '013645',\n",
       " '013646',\n",
       " '013647',\n",
       " '013648',\n",
       " '013649',\n",
       " '013650',\n",
       " '013651',\n",
       " '013652',\n",
       " '013653',\n",
       " '013654',\n",
       " '013655',\n",
       " '013656',\n",
       " '013657',\n",
       " '013658',\n",
       " '013659',\n",
       " '013660',\n",
       " '013661',\n",
       " '013662',\n",
       " '013663',\n",
       " '013664',\n",
       " '013665',\n",
       " '013666',\n",
       " '013667',\n",
       " '013668',\n",
       " '013669',\n",
       " '013670',\n",
       " '013671',\n",
       " '013672',\n",
       " '013673',\n",
       " '013674',\n",
       " '013675',\n",
       " '013676',\n",
       " '013677',\n",
       " '013678',\n",
       " '013679',\n",
       " '013680',\n",
       " '013681',\n",
       " '013682',\n",
       " '013684',\n",
       " '013685',\n",
       " '013686',\n",
       " '013687',\n",
       " '013688',\n",
       " '013690',\n",
       " '013691',\n",
       " '013692']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_validator import DatasetValidator\n",
    "data_validator = DatasetValidator('../datasets/LongSpeech_p2')\n",
    "ill_waveforms = data_validator.get_ill_waveforms()\n",
    "ill_waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e804e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ill_waveforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d0c7818",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_cuts = CutSet.from_jsonl(os.path.join(OUT_DIR, \"grouped_raw_cuts.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "309f8726",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cut_set = grouped_cuts.filter(lambda cut: cut.id in ill_waveforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6efa9a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_audios_from_cutset(cutset, out_dir, num_jobs=1):\n",
    "    \"\"\"\n",
    "    Save audios from a CutSet to the specified directory.\n",
    "    \"\"\"\n",
    "    for cut in tqdm(cutset):\n",
    "        cut.save_audio(os.path.join(out_dir, f\"{cut.id}.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce61ef15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [50:43<00:00, 23.60s/it]\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"LHOTSE_AUDIO_DURATION_MISMATCH_TOLERANCE\"] =   \"1.5\"\n",
    "save_audios_from_cutset(new_cut_set,os.path.join(OUT_DIR, 'wavs'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
