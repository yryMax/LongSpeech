{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T05:19:21.783167Z",
     "start_time": "2025-07-23T05:19:21.777863Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cuda:0\n",
      "/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"none\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import multiprocessing as mp\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from lhotse import CutSet, RecordingSet, SupervisionSet, MonoCut\n",
    "from mylhotse.iwslt_offlinetask import prepare_iwslt_offlinetask\n",
    "from lhotse.cut import append_cuts, MixedCut\n",
    "from lhotse.recipes import prepare_tedlium\n",
    "from util import *\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T03:56:20.456097Z",
     "start_time": "2025-07-23T03:56:18.419034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] skip ../datasets/LongSpeechSource/IWSLT.OfflineTask/data/en-de/tst2018: wav/ or ctms/ missing.\n",
      "[WARN] skip ../datasets/LongSpeechSource/IWSLT.OfflineTask/data/en-de/tst2019: wav/ or ctms/ missing.\n",
      "[WARN] skip ../datasets/LongSpeechSource/IWSLT.OfflineTask/data/en-de/tst2020: wav/ or ctms/ missing.\n",
      "[WARN] skip ../datasets/LongSpeechSource/IWSLT.OfflineTask/data/en-de/tst2021: wav/ or ctms/ missing.\n",
      "[WARN] skip ../datasets/LongSpeechSource/IWSLT.OfflineTask/data/en-de/tst2022: wav/ or ctms/ missing.\n"
     ]
    }
   ],
   "source": [
    "IN_DIR = \"../datasets/LongSpeechSource/IWSLT.OfflineTask\"\n",
    "OUT_DIR = '../datasets/LongSpeech_p2'\n",
    "manifests = prepare_iwslt_offlinetask(corpus_dir=Path(IN_DIR), output_dir=Path(OUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T03:56:28.308722Z",
     "start_time": "2025-07-23T03:56:28.282773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16071\n"
     ]
    }
   ],
   "source": [
    "config = json.load(open(os.path.join(OUT_DIR, 'metadata.json')))\n",
    "AVG_DURATION = config['avg_duration']\n",
    "SAMPLE_RATE = config['sample_rate']\n",
    "OUT_FILE_NAME = config['source']\n",
    "prev_amount = config['amount']\n",
    "print(prev_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:07:18.072774Z",
     "start_time": "2025-07-23T04:05:58.467390Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/lhotse/lazy.py:683: UserWarning: A lambda was passed to LazyMapper: it may prevent you from forking this process. If you experience issues with num_workers > 0 in torch.utils.data.DataLoader, try passing a regular function instead.\n",
      "  warnings.warn(\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "cuts = CutSet()\n",
    "for part in manifests.keys():\n",
    "    rs = manifests[part]['recordings']\n",
    "    ss = manifests[part]['supervisions']\n",
    "    ss_punc = ss.map(lambda seg: seg.transform_text(restore_punctuation))\n",
    "    cut = CutSet.from_manifests(recordings=rs, supervisions=ss_punc)\n",
    "    cuts += cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T03:56:41.400193Z",
     "start_time": "2025-07-23T03:56:41.305654Z"
    }
   },
   "outputs": [],
   "source": [
    "cuts.to_jsonl(os.path.join(OUT_DIR, f\"iwslt_raw_cuts.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:07:56.596818Z",
     "start_time": "2025-07-23T04:07:56.592385Z"
    }
   },
   "outputs": [],
   "source": [
    "def trim_silence_from_cut(cut):\n",
    "    \"\"\"\n",
    "    根据 supervision 信息修剪单个 Cut 的两端空白。\n",
    "    如果没有 supervision，则认为整个 cut 都是空白，返回 None。\n",
    "    \"\"\"\n",
    "    if not cut.supervisions:\n",
    "        return None\n",
    "\n",
    "    speech_start = min(s.start for s in cut.supervisions)\n",
    "    speech_end = max(s.end for s in cut.supervisions)\n",
    "\n",
    "    new_duration = speech_end - speech_start\n",
    "\n",
    "    if new_duration <= 0:\n",
    "        return None\n",
    "\n",
    "    return cut.truncate(offset=speech_start, duration=new_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:08:01.710226Z",
     "start_time": "2025-07-23T04:08:01.705752Z"
    }
   },
   "outputs": [],
   "source": [
    "cuts = cuts.map (\n",
    "    lambda cut: trim_silence_from_cut(cut)\n",
    ").filter(lambda cut: cut is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T05:32:53.344381Z",
     "start_time": "2025-07-23T05:32:53.339623Z"
    }
   },
   "outputs": [],
   "source": [
    "def pack_cuts_to_long_audio(\n",
    "    cuts: CutSet,\n",
    "    target_duration: float = 600.0,\n",
    "    staring_id =  0,\n",
    ") -> CutSet:\n",
    "    final_long_cuts = []\n",
    "    buffer_cut = None\n",
    "\n",
    "    for cut in cuts:\n",
    "        buffer_cut = buffer_cut.append(cut) if buffer_cut else cut\n",
    "\n",
    "        while buffer_cut.duration >= target_duration:\n",
    "            new_chunk = buffer_cut.truncate(offset=0, duration=target_duration)\n",
    "\n",
    "            new_chunk_id = new_chunk.with_id(f\"{staring_id:06d}\")\n",
    "            final_long_cuts.append(new_chunk_id)\n",
    "            staring_id += 1\n",
    "            buffer_cut = buffer_cut.truncate(offset=target_duration)\n",
    "\n",
    "    return CutSet.from_cuts(final_long_cuts), staring_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T05:32:54.920681Z",
     "start_time": "2025-07-23T05:32:54.811593Z"
    }
   },
   "outputs": [],
   "source": [
    "sliced_cuts, new_amount = pack_cuts_to_long_audio(cuts, target_duration=600.0, staring_id = prev_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T05:32:56.893095Z",
     "start_time": "2025-07-23T05:32:56.888654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16124"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T05:32:57.985315Z",
     "start_time": "2025-07-23T05:32:57.889253Z"
    }
   },
   "outputs": [],
   "source": [
    "sliced_cuts.to_jsonl(OUT_DIR + \"/iwslt_grouped_cuts.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T05:33:03.334862Z",
     "start_time": "2025-07-23T05:33:03.327738Z"
    }
   },
   "outputs": [],
   "source": [
    "def json_from_iwslt_to_allaudios(one_cut):\n",
    "    \"\"\"\n",
    "    Convert a single LibriSpeech json record to a list of LongSpeech metadata.\n",
    "    \"\"\"\n",
    "    sources = []\n",
    "    total_dur = 0\n",
    "    transcripts = []\n",
    "    slices = []\n",
    "    ttt = one_cut[\"tracks\"] if \"tracks\" in one_cut else [one_cut]\n",
    "    for subcut in ttt:\n",
    "        ccc = subcut[\"cut\"] if \"cut\" in subcut else subcut\n",
    "        total_dur += ccc[\"duration\"]\n",
    "        full_pth = ccc[\"recording\"][\"sources\"][0][\"source\"]\n",
    "        slices.append([ccc[\"start\"], ccc[\"duration\"]])\n",
    "        sources.append(full_pth.split(\"data\")[-1])\n",
    "        transcript_param = \" \".join([s[\"text\"] for s in ccc[\"supervisions\"] if s[\"text\"]])\n",
    "        if transcript_param != \"\":\n",
    "            transcripts.append(restore_punctuation(transcript_param))\n",
    "        else:\n",
    "            print(subcut)\n",
    "\n",
    "    return {\n",
    "        \"id\": one_cut[\"id\"],\n",
    "        \"source_ds\": \"iwslt\",\n",
    "        \"duration_sec\": total_dur,\n",
    "        \"audio_auto\": False,\n",
    "        \"text_auto\": False,\n",
    "        \"language\": 'en',\n",
    "        \"num_speakers\": len(sources),\n",
    "        \"num_switches\": len(sources),\n",
    "        \"slice\": slices,\n",
    "        \"transcribe\": \" \".join(transcripts),\n",
    "        \"components\": sources,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T05:33:04.931915Z",
     "start_time": "2025-07-23T05:33:04.928537Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_record(source_jsonl_path: str, target_jsonl_path: str, map_fn):\n",
    "    with open(source_jsonl_path, \"r\", encoding=\"utf-8\") as src_f, \\\n",
    "         open(target_jsonl_path, \"a\", encoding=\"utf-8\") as tgt_f:\n",
    "        for line in src_f:\n",
    "            item = json.loads(line)\n",
    "            new_item = map_fn(item)\n",
    "            tgt_f.write(json.dumps(new_item, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T05:33:26.769531Z",
     "start_time": "2025-07-23T05:33:06.062560Z"
    }
   },
   "outputs": [],
   "source": [
    "convert_record(os.path.join(OUT_DIR, \"iwslt_grouped_cuts.jsonl\"),\n",
    "               os.path.join(OUT_DIR, OUT_FILE_NAME),\n",
    "               json_from_iwslt_to_allaudios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T05:33:30.106885Z",
     "start_time": "2025-07-23T05:33:30.104054Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_audios_from_cutset(cutset, out_dir, num_jobs=1):\n",
    "    \"\"\"\n",
    "    Save audios from a CutSet to the specified directory.\n",
    "    \"\"\"\n",
    "    for cut in tqdm(cutset):\n",
    "        cut.save_audio(os.path.join(out_dir, f\"{cut.id}.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T05:35:17.367835Z",
     "start_time": "2025-07-23T05:33:31.410422Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:13<00:00,  4.04it/s]\n"
     ]
    }
   ],
   "source": [
    "save_audios_from_cutset(sliced_cuts, os.path.join(OUT_DIR, 'wavs'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
