{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-07-09T14:35:44.201530Z"
    },
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import argparse, multiprocessing as mp\n",
    "from pathlib import Path\n",
    "from util import *\n",
    "import os\n",
    "from lhotse import CutSet\n",
    "from lhotse.recipes import prepare_librispeech\n",
    "from lhotse.cut import append_cuts\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ffaeea9c29d5e89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:13:07.736735Z",
     "start_time": "2025-07-09T14:13:07.722913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2735\n"
     ]
    }
   ],
   "source": [
    "IN_DIR = \"../datasets/LongSpeechSource/LibriSpeech\"\n",
    "OUT_DIR = '../datasets/LongSpeech'\n",
    "config = json.load(open(os.path.join(OUT_DIR, 'metadata.json')))\n",
    "AVG_DURATION = config['avg_duration']\n",
    "SAMPLE_RATE = config['sample_rate']\n",
    "OUT_FILE_NAME = config['source']\n",
    "prev_amount = config['amount']\n",
    "print(prev_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69eafcd67642c075",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T13:59:10.582523Z",
     "start_time": "2025-07-09T13:58:14.271797Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset parts: 100%|██████████| 1/1 [00:43<00:00, 43.76s/it]\n"
     ]
    }
   ],
   "source": [
    "ds_part = 'train-clean-360'\n",
    "d =  prepare_librispeech(IN_DIR, OUT_DIR, dataset_parts=[ds_part], num_jobs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da9c2a5c586a4a9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:13:57.042467Z",
     "start_time": "2025-07-09T14:13:13.177705Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/renyi/miniconda3/envs/test3/lib/python3.10/site-packages/lhotse/lazy.py:683: UserWarning: A lambda was passed to LazyMapper: it may prevent you from forking this process. If you experience issues with num_workers > 0 in torch.utils.data.DataLoader, try passing a regular function instead.\n",
      "  warnings.warn(\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "rs = d[ds_part]['recordings']\n",
    "ss = d[ds_part]['supervisions']\n",
    "ss_punc = ss.map(lambda seg: seg.transform_text(restore_punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfec4816d7f678da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:19:15.528148Z",
     "start_time": "2025-07-09T14:19:15.242027Z"
    }
   },
   "outputs": [],
   "source": [
    "cuts = (CutSet.from_manifests(recordings=rs, supervisions=ss_punc)\n",
    ")\n",
    "\n",
    "cuts.to_jsonl(OUT_DIR + \"/raw_cuts.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6c187cb5f60d7b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:33:35.203963Z",
     "start_time": "2025-07-09T14:33:35.196693Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_and_group(\n",
    "        df: pd.DataFrame,\n",
    "        min_chapter_sec: int = 120,\n",
    "    ):\n",
    "\n",
    "    df = df[['id', 'duration']].copy()\n",
    "\n",
    "\n",
    "    parts = df['id'].str.split('-', expand=True)\n",
    "    df[['speaker', 'chapter', 'segment_num']] = parts[[0, 1, 2]]\n",
    "    df['segment_num'] = df['segment_num'].astype(int)\n",
    "    df['duration'] = df['duration'].astype(float)\n",
    "\n",
    "    long_enough = (\n",
    "        df.groupby(['speaker', 'chapter'])['duration']\n",
    "          .transform('sum') >= min_chapter_sec\n",
    "    )\n",
    "    df = df[long_enough].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def build_audio_groups(df: pd.DataFrame,\n",
    "                       target_sec: int = 600,\n",
    "                       tol_sec: int = 60,\n",
    "                       maximum_speakers: int = 3,\n",
    "                       maximum_switches: int = 3):\n",
    "    \"\"\"\n",
    "    将 df 中的片段拼成 ~target_sec 的组。\n",
    "    返回 (groups, summaries)\n",
    "    \"\"\"\n",
    "    # ① 预排序\n",
    "    df_sorted = df.sort_values(['speaker', 'chapter', 'segment_num']).reset_index(drop=True)\n",
    "\n",
    "    groups = []\n",
    "\n",
    "    cur_group, cur_dur = [], 0.0\n",
    "    cur_speakers = set()\n",
    "    semantic_changes = 0\n",
    "\n",
    "    prev_speaker, prev_chapter = None, None\n",
    "\n",
    "    for _, row in df_sorted.iterrows():\n",
    "        seg_id   = row['id']\n",
    "        dur      = float(row['duration'])\n",
    "        speaker  = row['speaker']\n",
    "        chapter  = row['chapter']\n",
    "\n",
    "        # 如果这个片段放进去会超出 target+tol，则先收尾\n",
    "        if cur_group and cur_dur + dur > target_sec + tol_sec:\n",
    "            if len(cur_speakers) <= maximum_speakers and semantic_changes <= maximum_switches:\n",
    "                groups.append((cur_group, len(cur_speakers), semantic_changes))\n",
    "\n",
    "            # reset\n",
    "            cur_group, cur_dur = [], 0.0\n",
    "            cur_speakers, semantic_changes = set(), 0\n",
    "            prev_speaker = prev_chapter = None\n",
    "\n",
    "        if prev_speaker is not None and prev_chapter is not None:\n",
    "            if speaker != prev_speaker or chapter != prev_chapter:\n",
    "                semantic_changes += 1\n",
    "\n",
    "        cur_group.append(seg_id)\n",
    "        cur_dur += dur\n",
    "        cur_speakers.add(speaker)\n",
    "\n",
    "        prev_speaker, prev_chapter = speaker, chapter\n",
    "\n",
    "    return groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a158909a3a0a11e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:34:56.575660Z",
     "start_time": "2025-07-09T14:34:56.282931Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "mock_strategy = [\n",
    "    ([\"1995-1836-0004-470\",\"4507-16021-0026-1247\"], 0, 1),\n",
    "    ([\"4970-29093-0006-1287\", \"5105-28233-0007-1413\"], 2, 3)\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "source_df = pd.read_json(OUT_DIR + \"/raw_cuts.jsonl\", lines=True)\n",
    "processed_df = prepare_and_group(df=source_df)\n",
    "real_strategy = build_audio_groups(processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62ad8d075845f649",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:35:07.659156Z",
     "start_time": "2025-07-09T14:35:07.650654Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_audios_from_cutset(cutset, out_dir, num_jobs=1):\n",
    "    \"\"\"\n",
    "    Save audios from a CutSet to the specified directory.\n",
    "    \"\"\"\n",
    "    for cut in tqdm(cutset):\n",
    "        cut.save_audio(os.path.join(out_dir, f\"{cut.id}.wav\"))\n",
    "\n",
    "\n",
    "def from_strategy_to_cuts(source_cuts, strategy: list, starting_cut_id=0):\n",
    "    \"\"\"\n",
    "    source_cuts: the cuts contains audio segments\n",
    "    strategy: a list of list of cut_ids\n",
    "    :return\n",
    "        target_cuts: the cuts after applying the combination strategy\n",
    "    \"\"\"\n",
    "    target_cuts_list = []\n",
    "    i = starting_cut_id\n",
    "    custom_feature = {}\n",
    "    for cluster_ids , num_speaker, num_switch in strategy:\n",
    "        cutlist = [source_cuts[cut_id] for cut_id in cluster_ids if cut_id in source_cuts]\n",
    "        new_cut = append_cuts(cutlist)\n",
    "        new_id = f\"{i:06d}\"\n",
    "        new_cut = new_cut.with_id(new_id)\n",
    "        target_cuts_list.append(new_cut)\n",
    "        custom_feature[new_id] = {\n",
    "            \"num_speakers\": num_speaker,\n",
    "            \"num_switches\": num_switch,\n",
    "        }\n",
    "        i += 1\n",
    "    return CutSet(target_cuts_list), custom_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13b2fbd5d914d34e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:35:13.137601Z",
     "start_time": "2025-07-09T14:35:12.612547Z"
    }
   },
   "outputs": [],
   "source": [
    "tgt_cuts, custom_feature = from_strategy_to_cuts(cuts, real_strategy, starting_cut_id = prev_amount)\n",
    "tgt_cuts.to_jsonl(OUT_DIR + \"/grouped_cuts.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6b4b7c0288a00be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:35:15.221069Z",
     "start_time": "2025-07-09T14:35:15.213416Z"
    }
   },
   "outputs": [],
   "source": [
    "def json_from_libri_to_allaudios(custom_feature, one_cut):\n",
    "    \"\"\"\n",
    "    Convert a single LibriSpeech json record to a list of LongSpeech metadata.\n",
    "    \"\"\"\n",
    "    sources = []\n",
    "    total_dur = 0\n",
    "    transcripts = []\n",
    "    for subcut in one_cut[\"tracks\"]:\n",
    "        total_dur += subcut[\"cut\"][\"duration\"]\n",
    "        full_pth = subcut[\"cut\"][\"recording\"][\"sources\"][0][\"source\"]\n",
    "        sources.append(full_pth.split(\"LibriSpeech\")[-1])\n",
    "        transcripts.append(subcut[\"cut\"][\"supervisions\"][0][\"text\"])\n",
    "\n",
    "    return {\n",
    "        \"id\": one_cut[\"id\"],\n",
    "        \"source_ds\": \"librispeech\",\n",
    "        \"duration_sec\": total_dur,\n",
    "        \"audio_auto\": False,\n",
    "        \"test_auto\": False,\n",
    "        \"num_speakers\": custom_feature.get(one_cut[\"id\"], {}).get(\"num_speakers\", -1),\n",
    "        \"num_switches\": custom_feature.get(one_cut[\"id\"], {}).get(\"num_switches\", -1),\n",
    "        \"transcribe\": \" \".join(transcripts),\n",
    "        \"components\": sources,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8bed8dfc896419f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:27:35.455577Z",
     "start_time": "2025-07-09T14:27:35.451624Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_record(source_jsonl_path: str, target_jsonl_path: str, custom_feature, map_fn):\n",
    "    with open(source_jsonl_path, \"r\", encoding=\"utf-8\") as src_f, \\\n",
    "         open(target_jsonl_path, \"a\", encoding=\"utf-8\") as tgt_f:\n",
    "        for line in src_f:\n",
    "            item = json.loads(line)\n",
    "            new_item = map_fn(custom_feature, item)\n",
    "            tgt_f.write(json.dumps(new_item, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa63137a22418002",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:27:36.914447Z",
     "start_time": "2025-07-09T14:27:36.899942Z"
    }
   },
   "outputs": [],
   "source": [
    "convert_record(os.path.join(OUT_DIR, \"grouped_cuts.jsonl\"),\n",
    "               os.path.join(OUT_DIR, OUT_FILE_NAME),\n",
    "               custom_feature,\n",
    "               json_from_libri_to_allaudios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e04e0549005883d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:30:41.756392Z",
     "start_time": "2025-07-09T14:30:41.277634Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 1427/2001 [29:20<14:25,  1.51s/it]"
     ]
    }
   ],
   "source": [
    "save_audios_from_cutset(tgt_cuts, os.path.join(OUT_DIR, 'wavs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d261883c7f1726a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef new_map_cut_id(cuts, starting_cut_id=0):\\n    new_cuts = (\\n        cut.with_id(f\"{starting_cut_id + i:06d}\")\\n        for i, cut in enumerate(cuts)\\n    )\\n    return CutSet.from_cuts(new_cuts).to_eager()\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "cutlist = []\n",
    "\n",
    "for cut in cuts:\n",
    "    if cut.duration > 10:  # Only keep cuts longer than 60 seconds\n",
    "        cutlist.append(cut)\n",
    "    if len(cutlist) >=5:\n",
    "        break\n",
    "new_cut = append_cuts(cutlist)\n",
    "new_cut.save_audio(os.path.join(OUT_DIR, 'wav/some.wav'))\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "def new_map_cut_id(cuts, starting_cut_id=0):\n",
    "    new_cuts = (\n",
    "        cut.with_id(f\"{starting_cut_id + i:06d}\")\n",
    "        for i, cut in enumerate(cuts)\n",
    "    )\n",
    "    return CutSet.from_cuts(new_cuts).to_eager()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
