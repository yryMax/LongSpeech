{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:39:58.339495Z",
     "start_time": "2025-07-17T03:39:58.321877Z"
    }
   },
   "source": [
    "import multiprocessing as mp\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from lhotse import CutSet, RecordingSet, SupervisionSet, MonoCut, combine\n",
    "from lhotse.recipes import prepare_commonvoice\n",
    "import logging\n",
    "from util import *\n",
    "import numpy as np\n",
    "import faiss, gc\n",
    "from lhotse_util import from_strategy_to_cuts, SpeakerEmbeddingExtractor\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import librosa\n",
    "from bitarray import bitarray\n",
    "from sklearn.decomposition import PCA"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "e3a1954a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:40:03.444594Z",
     "start_time": "2025-07-17T03:40:03.441945Z"
    }
   },
   "source": [
    "# directory paths to save audio and transcript files\n",
    "IN_DIR = \"../datasets/LongSpeechSource/voxpopuli\"\n",
    "IN_DIR = \"/mnt/d/voicedata/CommenVoice/delta\"\n",
    "# directory paths to save metadata and processed aduio files\n",
    "OUT_DIR = '../datasets/LongSpeech'"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "config_setup",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:40:05.191837Z",
     "start_time": "2025-07-17T03:40:05.183396Z"
    }
   },
   "source": [
    "config = json.load(open(os.path.join(OUT_DIR, 'metadata.json')))\n",
    "AVG_DURATION = config['avg_duration']\n",
    "SAMPLE_RATE = config['sample_rate']\n",
    "OUT_FILE_NAME = config['source']\n",
    "prev_amount = config['amount']\n",
    "print(prev_amount)\n",
    "task = \"asr\"\n",
    "lang = \"en\""
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:33:50.552508Z",
     "start_time": "2025-07-17T03:33:44.494337Z"
    }
   },
   "cell_type": "code",
   "source": "manifests = prepare_commonvoice(corpus_dir=IN_DIR, output_dir=OUT_DIR, languages = 'en', splits=['validated'])",
   "id": "3de79901c45e3eb2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Processing CommonVoice languages:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2d5162bad404d6c9383257c9d473a97"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Language: en\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Spliting:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ea24d91926e40a9b0ea8c4a77becc4f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Spliting validated\n",
      "INFO:root:The user overrided the global setting for whether to use ffmpeg-torchaudio to compute the duration of audio files. Old setting: True. New setting: False.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Distributing tasks: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82678e19e98b420fb653c012fe97aea8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Processing:   0%|          | 0/170 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e83142ef30a6476a8dd34c9504c9edf5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:The user overrided the global setting for whether to use ffmpeg-torchaudio to compute the duration of audio files. Old setting: False. New setting: True.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:33:52.634656Z",
     "start_time": "2025-07-17T03:33:52.629306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "cuts = CutSet()\n",
    "for part in manifests.keys():\n",
    "    rs = manifests[part]['validated']['recordings']\n",
    "    ss = manifests[part]['validated']['supervisions']\n",
    "    cut = CutSet.from_manifests(recordings=rs, supervisions=ss)\n",
    "    cuts += cut"
   ],
   "id": "ccdae1870680c1ca",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:34:24.069442Z",
     "start_time": "2025-07-17T03:34:24.025202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resampled_cuts = cuts.filter(lambda cut: cut.duration > 3).resample(SAMPLE_RATE).to_eager()\n",
    "resampled_cuts.to_jsonl(os.path.join(OUT_DIR, \"commonvoice_raw_cuts.jsonl\"))"
   ],
   "id": "3f8b3bcc268d9c30",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:40:17.403393Z",
     "start_time": "2025-07-17T03:40:17.392645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_feature(cuts: CutSet, batch_size: int = 100, dim: int = 384):\n",
    "    cut_list = cuts.to_eager()\n",
    "    n = len(cut_list)\n",
    "\n",
    "    vec_mm = np.memmap(f\"{OUT_DIR}/vecs.f32\", dtype=\"float32\", mode=\"w+\", shape=(n, dim))\n",
    "    dur_mm = np.memmap(f\"{OUT_DIR}/durs.f32\", dtype=\"float32\", mode=\"w+\", shape=(n,))\n",
    "\n",
    "    string_ids = []\n",
    "\n",
    "    ptr = 0\n",
    "    for i in tqdm(range(0, n, batch_size), desc=\"Get Embedding\"):\n",
    "        cut_batch = cut_list[i:i+batch_size]\n",
    "\n",
    "        texts = [c.supervisions[0].text if c.supervisions else \"\" for c in cut_batch]\n",
    "        durations = [c.duration for c in cut_batch]\n",
    "        string_ids.extend([c.id for c in cut_batch])\n",
    "\n",
    "        vec_np = get_sentence_embeddings(texts).astype(\"float32\")\n",
    "        B = len(cut_batch)\n",
    "\n",
    "        vec_mm[ptr:ptr+B] = vec_np\n",
    "        dur_mm[ptr:ptr+B] = durations\n",
    "        ptr += B\n",
    "\n",
    "    vec_mm.flush(); dur_mm.flush()\n",
    "\n",
    "    return vec_mm, dur_mm, string_ids\n",
    "\n",
    "def build_hnsw_index(vec_mm: np.memmap,\n",
    "                     dim: int = 384,\n",
    "                     m: int = 32,\n",
    "                     ef_c: int = 200,\n",
    "                     n_threads: int = mp.cpu_count(),\n",
    "                     out_path: str = \"cache_hnsw.faiss\"):\n",
    "\n",
    "    faiss.omp_set_num_threads(n_threads)\n",
    "    faiss.normalize_L2(vec_mm)\n",
    "\n",
    "    index = faiss.IndexHNSWFlat(dim, m)\n",
    "    index.hnsw.efConstruction = ef_c\n",
    "    index.metric_type = faiss.METRIC_INNER_PRODUCT\n",
    "\n",
    "    index.add(vec_mm)\n",
    "    faiss.write_index(index, os.path.join(OUT_DIR,out_path))\n",
    "    return os.path.join(OUT_DIR,out_path)\n",
    "\n",
    "def get_speaker_embedding_ids(ids, neighs, cuts):\n",
    "    \"\"\"\n",
    "    获取邻居的说话人ID\n",
    "    Returns:\n",
    "        speaker_embeddings: (batch_num, feature_dim)\n",
    "    \"\"\"\n",
    "    speaker_embeddings = []\n",
    "    for idx in neighs:\n",
    "        if idx == -1:\n",
    "            break\n",
    "        real_id = ids[idx]\n",
    "        cut_pth = cuts[real_id].recording.sources[0].source\n",
    "        audio, sr = librosa.load(cut_pth)\n",
    "        speaker_embeddings.append(get_speaker_embedding(audio, sr).flatten())\n",
    "\n",
    "    spk_emb_np = np.array(speaker_embeddings)\n",
    "    pc1 = PCA(n_components=1, svd_solver=\"auto\").fit_transform(spk_emb_np).ravel()\n",
    "    return np.argsort(pc1)\n",
    "\n",
    "def greedy_cluster(index_path: str,\n",
    "                   vec_mm: np.memmap,\n",
    "                   dur_mm: np.memmap,\n",
    "                   ids,\n",
    "                   cuts,\n",
    "                   bucket_min: int = 300,\n",
    "                   bucket_avg: int = 600,\n",
    "                   k_neigh: int = 1024,\n",
    "                   ef_s: int = 96):\n",
    "    index = faiss.read_index(index_path)\n",
    "\n",
    "    params = faiss.SearchParametersHNSW()\n",
    "    params.efSearch = ef_s\n",
    "\n",
    "    N = len(vec_mm)\n",
    "    assigned = bitarray(N)\n",
    "    assigned.setall(False)\n",
    "\n",
    "    order = np.argsort(-dur_mm)\n",
    "    buckets = []\n",
    "\n",
    "    for seed in tqdm(order, desc=\"Clustering (Optimized)\"):\n",
    "        if assigned[seed]:\n",
    "            continue\n",
    "\n",
    "        cluster = []\n",
    "        total_dur = 0\n",
    "\n",
    "        unassigned_indices_list = assigned.search(bitarray('0'))\n",
    "        unassigned_indices = np.fromiter(unassigned_indices_list, dtype=np.int64)\n",
    "\n",
    "\n",
    "        if len(unassigned_indices) > 0:\n",
    "            selector = faiss.IDSelectorArray(unassigned_indices)\n",
    "            params.sel = selector\n",
    "\n",
    "            _, neighs = index.search(vec_mm[seed : seed + 1], k_neigh, params=params)\n",
    "\n",
    "            speaker_order = get_speaker_embedding_ids(ids, neighs[0].tolist(), cuts)\n",
    "            #print(speaker_order)\n",
    "\n",
    "            for idx2 in speaker_order:\n",
    "                idx = neighs[0][idx2]\n",
    "                if idx == -1:\n",
    "                    break\n",
    "                if assigned[idx]:\n",
    "                    print(\"Warning: Already assigned index\", idx)\n",
    "                    continue\n",
    "\n",
    "                cluster.append(int(idx))\n",
    "                assigned[idx] = True\n",
    "                total_dur += dur_mm[idx]\n",
    "                if total_dur >= bucket_avg:\n",
    "                    break\n",
    "\n",
    "            if total_dur < bucket_min:\n",
    "                for i in cluster:\n",
    "                    assigned[i] = False\n",
    "            else:\n",
    "                total_dur = dur_mm[cluster].sum()\n",
    "                buckets.append((cluster, total_dur))\n",
    "\n",
    "    final_buckets = [b for b in buckets if b[1] >= bucket_min]\n",
    "    final_clusters = [c for c, _ in final_buckets]\n",
    "    final_duration = sum(sec for _, sec in final_buckets)\n",
    "\n",
    "    loss = 1 - final_duration / dur_mm.sum()\n",
    "    print(f\"桶数 {len(final_clusters)}, 最终时长 {final_duration:.2f}s, 总时长 {dur_mm.sum():.2f}s, 丢弃比例 {loss:.2%}\")\n",
    "\n",
    "    strategy = []\n",
    "    for cluster in final_clusters:\n",
    "        strategy.append([ids[i] for i in cluster])\n",
    "\n",
    "    return strategy"
   ],
   "id": "98e124a17f4c3bba",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:46:26.001705Z",
     "start_time": "2025-07-17T03:42:03.747620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "mock_strategy = [\n",
    "    [\"common_voice_en_43199993-0\", \"common_voice_en_42736613-1\", \"common_voice_en_42798328-2\"],\n",
    "    [\"common_voice_en_43204215-3\", \"common_voice_en_42706055-4\", \"common_voice_en_43139615-5\"]\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "vec_mm, dur_mm, string_ids = build_feature(resampled_cuts)\n",
    "index_path = build_hnsw_index(vec_mm)\n",
    "real_strategy = greedy_cluster(index_path, vec_mm, dur_mm, string_ids, resampled_cuts)"
   ],
   "id": "a25e121040a3ae99",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get Embedding:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b249f68ce4ac4d2d848918af3b3511d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get Embedding:  50%|█████     | 1/2 [00:01<00:01,  1.95s/it]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "761e58d7ab1140d7a28610eae7a51d10"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get Embedding: 100%|██████████| 2/2 [00:02<00:00,  1.01s/it]\n",
      "Clustering (Optimized):   0%|          | 0/168 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Clustering (Optimized): 100%|██████████| 168/168 [04:20<00:00,  1.55s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "桶数 2, 最终时长 1027.54s, 总时长 1027.54s, 丢弃比例 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:47:26.345595Z",
     "start_time": "2025-07-17T03:47:26.341492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def map_newid_cutset(cutset: CutSet, start_id: int = 0) -> CutSet:\n",
    "    \"\"\"\n",
    "    Map the ids of a CutSet to a new id starting from start_id.\n",
    "    \"\"\"\n",
    "    new_cuts = []\n",
    "    for i, cut in enumerate(cutset):\n",
    "        new_cut = cut.with_id(f\"{start_id + i:06d}\")\n",
    "        new_cuts.append(new_cut)\n",
    "    return CutSet.from_cuts(new_cuts), start_id + len(new_cuts)"
   ],
   "id": "86e2d3ce5edad1ff",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:47:29.071564Z",
     "start_time": "2025-07-17T03:47:29.038806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grouped_cuts = from_strategy_to_cuts(resampled_cuts.to_eager(), real_strategy)\n",
    "grouped_cuts , new_amount = map_newid_cutset(grouped_cuts, start_id=prev_amount)\n",
    "grouped_cuts.to_jsonl(os.path.join(OUT_DIR, \"grouped_raw_cuts.jsonl\"))\n",
    "print(new_amount)"
   ],
   "id": "93d35bb307c93c85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:47:31.462411Z",
     "start_time": "2025-07-17T03:47:31.449615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def json_from_commonvoice_to_allaudios(one_cut, lang = \"en\"):\n",
    "    \"\"\"\n",
    "    Convert a single Commonvoice json record to a list of LongSpeech metadata.\n",
    "    \"\"\"\n",
    "    sources = []\n",
    "    speakers = set()\n",
    "    total_dur = 0\n",
    "    transcripts = []\n",
    "    slices = []\n",
    "\n",
    "    for subcut in one_cut[\"tracks\"]:\n",
    "        total_dur += subcut[\"cut\"][\"duration\"]\n",
    "        full_pth = subcut[\"cut\"][\"recording\"][\"sources\"][0][\"source\"]\n",
    "        slices.append([subcut[\"cut\"][\"start\"], subcut[\"cut\"][\"duration\"]])\n",
    "        sources.append(full_pth.split(\"clips\")[-1])\n",
    "        [speakers.add(s[\"speaker\"]) for s in subcut[\"cut\"][\"supervisions\"] if s[\"speaker\"]]\n",
    "        transcript_param = \" \".join([s[\"text\"] for s in subcut[\"cut\"][\"supervisions\"] if s[\"text\"]])\n",
    "        if transcript_param != \"\":\n",
    "            transcripts.append(transcript_param)\n",
    "        else:\n",
    "            print(subcut)\n",
    "\n",
    "    return {\n",
    "        \"id\": one_cut[\"id\"],\n",
    "        \"source_ds\": \"CommonVoice\",\n",
    "        \"duration_sec\": total_dur,\n",
    "        \"audio_auto\": False,\n",
    "        \"text_auto\": False,\n",
    "        \"language\": lang,\n",
    "        \"num_speakers\": len(speakers),\n",
    "        \"num_switches\": len(transcripts),\n",
    "        \"slice\": slices,\n",
    "        \"transcribe\": \" \".join(transcripts),\n",
    "        \"components\": sources,\n",
    "    }\n",
    "\n",
    "\n",
    "def convert_record(source_jsonl_path: str, target_jsonl_path: str, map_fn, lang: str):\n",
    "    with open(source_jsonl_path, \"r\", encoding=\"utf-8\") as src_f, \\\n",
    "         open(target_jsonl_path, \"a\", encoding=\"utf-8\") as tgt_f:\n",
    "        for line in src_f:\n",
    "            item = json.loads(line)\n",
    "            new_item = map_fn(item, lang)\n",
    "            tgt_f.write(json.dumps(new_item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def save_audios_from_cutset(cutset, out_dir, num_jobs=1):\n",
    "    \"\"\"\n",
    "    Save audios from a CutSet to the specified directory.\n",
    "    \"\"\"\n",
    "    for cut in tqdm(cutset):\n",
    "        cut.save_audio(os.path.join(out_dir, f\"{cut.id}.wav\"))\n"
   ],
   "id": "419954e0b702973b",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:48:09.821171Z",
     "start_time": "2025-07-17T03:47:34.637295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "convert_record(os.path.join(OUT_DIR, \"grouped_raw_cuts.jsonl\"),\n",
    "               os.path.join(OUT_DIR, OUT_FILE_NAME),\n",
    "               json_from_commonvoice_to_allaudios, lang)\n",
    "save_audios_from_cutset(grouped_cuts, os.path.join(OUT_DIR, 'wavs'))"
   ],
   "id": "fd73da044d6b28be",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:35<00:00, 17.58s/it]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:49:03.069293Z",
     "start_time": "2025-07-17T03:49:03.063462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "def with_new_features(cuts: CutSet, batch_size = 100) -> CutSet:\n",
    "    cutset_list = cuts.split_lazy(OUT_DIR, batch_size)\n",
    "    new_cutset_list = []\n",
    "    for i, cutset in enumerate(tqdm(cutset_list, desc=\"Processing cuts\")):\n",
    "        text_list = [cut.supervisions[0].text if cut.supervisions else \"\" for cut in cutset]\n",
    "        id_list = [cut.id for cut in cutset]\n",
    "        duration = [cut.duration for cut in cutset]\n",
    "        semantic_np = get_sentence_embeddings(\n",
    "            text_list\n",
    "        )\n",
    "\n",
    "        updated_cuts = []\n",
    "        for cut, embedding in zip(cutset, semantic_np):\n",
    "            cut = cut.with_custom(\"semantic_emb\", embedding.tolist())  # 如果是 numpy array\n",
    "            updated_cuts.append(cut)\n",
    "\n",
    "\n",
    "        new_cutset_list.append(CutSet.from_cuts(updated_cuts))\n",
    "    merged_cuts = combine(*new_cutset_list)\n",
    "    return merged_cuts\n",
    "\"\"\""
   ],
   "id": "fbe4c66ba1092b59",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef with_new_features(cuts: CutSet, batch_size = 100) -> CutSet:\\n    cutset_list = cuts.split_lazy(OUT_DIR, batch_size)\\n    new_cutset_list = []\\n    for i, cutset in enumerate(tqdm(cutset_list, desc=\"Processing cuts\")):\\n        text_list = [cut.supervisions[0].text if cut.supervisions else \"\" for cut in cutset]\\n        id_list = [cut.id for cut in cutset]\\n        duration = [cut.duration for cut in cutset]\\n        semantic_np = get_sentence_embeddings(\\n            text_list\\n        )\\n\\n        updated_cuts = []\\n        for cut, embedding in zip(cutset, semantic_np):\\n            cut = cut.with_custom(\"semantic_emb\", embedding.tolist())  # 如果是 numpy array\\n            updated_cuts.append(cut)\\n\\n\\n        new_cutset_list.append(CutSet.from_cuts(updated_cuts))\\n    merged_cuts = combine(*new_cutset_list)\\n    return merged_cuts\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
