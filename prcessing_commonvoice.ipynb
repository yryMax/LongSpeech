{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:08:44.775600Z",
     "start_time": "2025-07-17T08:08:44.770743Z"
    }
   },
   "source": [
    "import multiprocessing as mp\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from lhotse import CutSet\n",
    "from lhotse.recipes import prepare_commonvoice\n",
    "import logging\n",
    "from util import *\n",
    "import numpy as np\n",
    "import faiss, gc\n",
    "from lhotse_util import from_strategy_to_cuts\n",
    "from lhotse.cut import append_cuts\n",
    "import librosa\n",
    "from bitarray import bitarray\n",
    "from sklearn.decomposition import PCA"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "e3a1954a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:11:12.672199Z",
     "start_time": "2025-07-17T08:11:12.669168Z"
    }
   },
   "source": [
    "# directory paths to save audio and transcript files\n",
    "IN_DIR = \"../datasets/LongSpeechSource/cv-corpus-22.0-2025-06-20\"\n",
    "IN_DIR = \"/mnt/d/voicedata/CommenVoice/delta\"\n",
    "# directory paths to save metadata and processed aduio files\n",
    "OUT_DIR = '../datasets/LongSpeech'"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "config_setup",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:11:14.165259Z",
     "start_time": "2025-07-17T08:11:14.150207Z"
    }
   },
   "source": [
    "config = json.load(open(os.path.join(OUT_DIR, 'metadata.json')))\n",
    "AVG_DURATION = config['avg_duration']\n",
    "SAMPLE_RATE = config['sample_rate']\n",
    "OUT_FILE_NAME = config['source']\n",
    "prev_amount = config['amount']\n",
    "print(prev_amount)\n",
    "task = \"asr\""
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "3de79901c45e3eb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:11:39.838638Z",
     "start_time": "2025-07-17T08:11:31.420894Z"
    }
   },
   "source": [
    "lang = \"en\"\n",
    "manifests = prepare_commonvoice(corpus_dir=IN_DIR, output_dir=OUT_DIR, languages = lang , splits=['validated'], num_jobs=15)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Processing CommonVoice languages:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52dd24adb7f5472cb9b4a0543434394d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spliting:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "17c33ab0ad224e249fe56fbe550e957d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Distributing tasks: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb30d02344de423799a9a8203099504e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Processing:   0%|          | 0/170 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "66e253b0d42f49b9a74ce807b1336f19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "ccdae1870680c1ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:11:42.323629Z",
     "start_time": "2025-07-17T08:11:42.315342Z"
    }
   },
   "source": [
    "\n",
    "cuts = CutSet()\n",
    "for part in manifests.keys():\n",
    "    rs = manifests[part]['validated']['recordings']\n",
    "    ss = manifests[part]['validated']['supervisions']\n",
    "    cut = CutSet.from_manifests(recordings=rs, supervisions=ss)\n",
    "    cuts += cut"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "3f8b3bcc268d9c30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:11:46.345764Z",
     "start_time": "2025-07-17T08:11:46.283473Z"
    }
   },
   "source": [
    "resampled_cuts = cuts.filter(lambda cut: cut.duration > 3).resample(SAMPLE_RATE).to_eager()\n",
    "resampled_cuts.to_jsonl(os.path.join(OUT_DIR, \"commonvoice_raw_cuts.jsonl\"))"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "98e124a17f4c3bba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:11:48.581933Z",
     "start_time": "2025-07-17T08:11:48.569025Z"
    }
   },
   "source": [
    "def build_feature(cuts: CutSet, batch_size: int = 100, dim: int = 384):\n",
    "    cut_list = cuts.to_eager()\n",
    "    n = len(cut_list)\n",
    "\n",
    "    vec_mm = np.memmap(f\"{OUT_DIR}/vecs.f32\", dtype=\"float32\", mode=\"w+\", shape=(n, dim))\n",
    "    dur_mm = np.memmap(f\"{OUT_DIR}/durs.f32\", dtype=\"float32\", mode=\"w+\", shape=(n,))\n",
    "\n",
    "    string_ids = []\n",
    "\n",
    "    ptr = 0\n",
    "    for i in tqdm(range(0, n, batch_size), desc=\"Get Embedding\"):\n",
    "        cut_batch = cut_list[i:i+batch_size]\n",
    "\n",
    "        texts = [c.supervisions[0].text if c.supervisions else \"\" for c in cut_batch]\n",
    "        durations = [c.duration for c in cut_batch]\n",
    "        string_ids.extend([c.id for c in cut_batch])\n",
    "\n",
    "        vec_np = get_sentence_embeddings(texts).astype(\"float32\")\n",
    "        B = len(cut_batch)\n",
    "\n",
    "        vec_mm[ptr:ptr+B] = vec_np\n",
    "        dur_mm[ptr:ptr+B] = durations\n",
    "        ptr += B\n",
    "\n",
    "    vec_mm.flush(); dur_mm.flush()\n",
    "\n",
    "    return vec_mm, dur_mm, string_ids\n",
    "\n",
    "def build_hnsw_index(vec_mm: np.memmap,\n",
    "                     dim: int = 384,\n",
    "                     m: int = 32,\n",
    "                     ef_c: int = 200,\n",
    "                     n_threads: int = mp.cpu_count(),\n",
    "                     out_path: str = \"cache_hnsw.faiss\"):\n",
    "\n",
    "    faiss.omp_set_num_threads(n_threads)\n",
    "    faiss.normalize_L2(vec_mm)\n",
    "\n",
    "    index = faiss.IndexHNSWFlat(dim, m)\n",
    "    index.hnsw.efConstruction = ef_c\n",
    "    index.metric_type = faiss.METRIC_INNER_PRODUCT\n",
    "\n",
    "    index.add(vec_mm)\n",
    "    faiss.write_index(index, os.path.join(OUT_DIR,out_path))\n",
    "    return os.path.join(OUT_DIR,out_path)\n",
    "\n",
    "def get_speaker_embedding_ids(ids, neighs, cuts):\n",
    "    \"\"\"\n",
    "    获取邻居的说话人ID\n",
    "    Returns:\n",
    "        speaker_embeddings: (batch_num, feature_dim)\n",
    "    \"\"\"\n",
    "    speaker_embeddings = []\n",
    "    for idx in neighs:\n",
    "        if idx == -1:\n",
    "            break\n",
    "        real_id = ids[idx]\n",
    "        cut_pth = cuts[real_id].recording.sources[0].source\n",
    "        audio, sr = librosa.load(cut_pth)\n",
    "        speaker_embeddings.append(get_speaker_embedding(audio, sr).flatten())\n",
    "\n",
    "    spk_emb_np = np.array(speaker_embeddings)\n",
    "    pc1 = PCA(n_components=1, svd_solver=\"auto\").fit_transform(spk_emb_np).ravel()\n",
    "    return np.argsort(pc1)\n",
    "\n",
    "def greedy_cluster(index_path: str,\n",
    "                   vec_mm: np.memmap,\n",
    "                   dur_mm: np.memmap,\n",
    "                   ids,\n",
    "                   cuts,\n",
    "                   bucket_min: int = 480,\n",
    "                   bucket_avg: int = 600,\n",
    "                   k_neigh: int = 256,\n",
    "                   ef_s: int = 96):\n",
    "    index = faiss.read_index(index_path)\n",
    "\n",
    "    params = faiss.SearchParametersHNSW()\n",
    "    params.efSearch = ef_s\n",
    "\n",
    "    N = len(vec_mm)\n",
    "    assigned = bitarray(N)\n",
    "    assigned.setall(False)\n",
    "\n",
    "    order = np.argsort(-dur_mm)\n",
    "    buckets = []\n",
    "\n",
    "    for seed in tqdm(order, desc=\"Clustering (Optimized)\"):\n",
    "        if assigned[seed]:\n",
    "            continue\n",
    "\n",
    "        cluster = []\n",
    "        total_dur = 0\n",
    "\n",
    "        unassigned_indices_list = assigned.search(bitarray('0'))\n",
    "        unassigned_indices = np.fromiter(unassigned_indices_list, dtype=np.int64)\n",
    "\n",
    "\n",
    "        if len(unassigned_indices) > 0:\n",
    "            selector = faiss.IDSelectorArray(unassigned_indices)\n",
    "            params.sel = selector\n",
    "\n",
    "            _, neighs = index.search(vec_mm[seed : seed + 1], k_neigh, params=params)\n",
    "\n",
    "            #speaker_order = get_speaker_embedding_ids(ids, neighs[0].tolist(), cuts)\n",
    "            #print(speaker_order)\n",
    "\n",
    "            for idx in neighs[0]:\n",
    "                if idx == -1:\n",
    "                    break\n",
    "                if assigned[idx]:\n",
    "                    print(\"Warning: Already assigned index\", idx)\n",
    "                    continue\n",
    "\n",
    "                cluster.append(int(idx))\n",
    "                assigned[idx] = True\n",
    "                total_dur += dur_mm[idx]\n",
    "                if total_dur >= bucket_avg:\n",
    "                    break\n",
    "\n",
    "            if total_dur < bucket_min:\n",
    "                for i in cluster:\n",
    "                    assigned[i] = False\n",
    "            else:\n",
    "                total_dur = dur_mm[cluster].sum()\n",
    "                buckets.append((cluster, total_dur))\n",
    "\n",
    "    final_buckets = [b for b in buckets if b[1] >= bucket_min]\n",
    "    final_clusters = [c for c, _ in final_buckets]\n",
    "    final_duration = sum(sec for _, sec in final_buckets)\n",
    "\n",
    "    loss = 1 - final_duration / dur_mm.sum()\n",
    "    print(f\"桶数 {len(final_clusters)}, 最终时长 {final_duration:.2f}s, 总时长 {dur_mm.sum():.2f}s, 丢弃比例 {loss:.2%}\")\n",
    "\n",
    "    strategy = []\n",
    "    for cluster in final_clusters:\n",
    "        strategy.append([ids[i] for i in cluster])\n",
    "\n",
    "    return strategy"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "a25e121040a3ae99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:11:59.105798Z",
     "start_time": "2025-07-17T08:11:55.728856Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "mock_strategy = [\n",
    "    [\"common_voice_en_43199993-0\", \"common_voice_en_42736613-1\", \"common_voice_en_42798328-2\"],\n",
    "    [\"common_voice_en_43204215-3\", \"common_voice_en_42706055-4\", \"common_voice_en_43139615-5\"]\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "vec_mm, dur_mm, string_ids = build_feature(resampled_cuts)\n",
    "index_path = build_hnsw_index(vec_mm)\n",
    "real_strategy = greedy_cluster(index_path, vec_mm, dur_mm, string_ids, resampled_cuts)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get Embedding: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]\n",
      "Clustering (Optimized): 100%|██████████| 168/168 [00:00<00:00, 433.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "桶数 1, 最终时长 601.77s, 总时长 1027.54s, 丢弃比例 41.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "86e2d3ce5edad1ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:12:16.937733Z",
     "start_time": "2025-07-17T08:12:16.933116Z"
    }
   },
   "source": [
    "def map_newid_cutset(cutset: CutSet, start_id: int = 0) -> CutSet:\n",
    "    \"\"\"\n",
    "    Map the ids of a CutSet to a new id starting from start_id.\n",
    "    \"\"\"\n",
    "    new_cuts = []\n",
    "    for i, cut in enumerate(cutset):\n",
    "        new_cut = cut.with_id(f\"{start_id + i:06d}\")\n",
    "        new_cuts.append(new_cut)\n",
    "    return CutSet.from_cuts(new_cuts), start_id + len(new_cuts)\n",
    "\n",
    "def build_grouped_cuts(\n",
    "        source_cuts: CutSet,\n",
    "        strategy,\n",
    "        start_id: int = 0\n",
    "    ):\n",
    "\n",
    "    src = {c.id: c for c in source_cuts}\n",
    "\n",
    "    grouped = []\n",
    "    next_id = start_id\n",
    "    for cluster_ids in strategy:\n",
    "        cuts = [src[cid] for cid in cluster_ids]\n",
    "        merged = append_cuts(cuts).with_id(f\"{next_id:06d}\")\n",
    "        grouped.append(merged)\n",
    "        next_id += 1\n",
    "\n",
    "    return CutSet.from_cuts(grouped), next_id"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "93d35bb307c93c85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T08:12:20.057668Z",
     "start_time": "2025-07-17T08:12:20.048215Z"
    }
   },
   "source": [
    "#grouped_cuts = from_strategy_to_cuts(resampled_cuts.to_eager(), real_strategy)\n",
    "#grouped_cuts , new_amount = map_newid_cutset(grouped_cuts, start_id=prev_amount)\n",
    "\n",
    "grouped_cuts, new_amount = build_grouped_cuts(resampled_cuts, real_strategy, start_id=prev_amount)\n",
    "#grouped_cuts.to_jsonl(os.path.join(OUT_DIR, \"grouped_raw_cuts.jsonl\"))\n",
    "print(new_amount)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419954e0b702973b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:47:31.462411Z",
     "start_time": "2025-07-17T03:47:31.449615Z"
    }
   },
   "outputs": [],
   "source": [
    "def json_from_commonvoice_to_allaudios(one_cut, lang = \"en\"):\n",
    "    \"\"\"\n",
    "    Convert a single Commonvoice json record to a list of LongSpeech metadata.\n",
    "    \"\"\"\n",
    "    sources = []\n",
    "    speakers = set()\n",
    "    total_dur = 0\n",
    "    transcripts = []\n",
    "    slices = []\n",
    "\n",
    "    for subcut in one_cut[\"tracks\"]:\n",
    "        total_dur += subcut[\"cut\"][\"duration\"]\n",
    "        full_pth = subcut[\"cut\"][\"recording\"][\"sources\"][0][\"source\"]\n",
    "        slices.append([subcut[\"cut\"][\"start\"], subcut[\"cut\"][\"duration\"]])\n",
    "        sources.append(full_pth.split(\"clips\")[-1])\n",
    "        [speakers.add(s[\"speaker\"]) for s in subcut[\"cut\"][\"supervisions\"] if s[\"speaker\"]]\n",
    "        transcript_param = \" \".join([s[\"text\"] for s in subcut[\"cut\"][\"supervisions\"] if s[\"text\"]])\n",
    "        if transcript_param != \"\":\n",
    "            transcripts.append(transcript_param)\n",
    "        else:\n",
    "            print(subcut)\n",
    "\n",
    "    return {\n",
    "        \"id\": one_cut[\"id\"],\n",
    "        \"source_ds\": \"CommonVoice\",\n",
    "        \"duration_sec\": total_dur,\n",
    "        \"audio_auto\": False,\n",
    "        \"text_auto\": False,\n",
    "        \"language\": lang,\n",
    "        \"num_speakers\": len(speakers),\n",
    "        \"num_switches\": len(transcripts),\n",
    "        \"slice\": slices,\n",
    "        \"transcribe\": \" \".join(transcripts),\n",
    "        \"components\": sources,\n",
    "    }\n",
    "\n",
    "\n",
    "def convert_record(source_jsonl_path: str, target_jsonl_path: str, map_fn, lang: str):\n",
    "    with open(source_jsonl_path, \"r\", encoding=\"utf-8\") as src_f, \\\n",
    "         open(target_jsonl_path, \"a\", encoding=\"utf-8\") as tgt_f:\n",
    "        for line in src_f:\n",
    "            item = json.loads(line)\n",
    "            new_item = map_fn(item, lang)\n",
    "            tgt_f.write(json.dumps(new_item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def save_audios_from_cutset(cutset, out_dir, num_jobs=1):\n",
    "    \"\"\"\n",
    "    Save audios from a CutSet to the specified directory.\n",
    "    \"\"\"\n",
    "    for cut in tqdm(cutset):\n",
    "        cut.save_audio(os.path.join(out_dir, f\"{cut.id}.wav\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73da044d6b28be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:48:09.821171Z",
     "start_time": "2025-07-17T03:47:34.637295Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:35<00:00, 17.58s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "convert_record(os.path.join(OUT_DIR, \"grouped_raw_cuts.jsonl\"),\n",
    "               os.path.join(OUT_DIR, OUT_FILE_NAME),\n",
    "               json_from_commonvoice_to_allaudios, lang)\n",
    "#save_audios_from_cutset(grouped_cuts, os.path.join(OUT_DIR, 'wavs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe4c66ba1092b59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T03:49:03.069293Z",
     "start_time": "2025-07-17T03:49:03.063462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef with_new_features(cuts: CutSet, batch_size = 100) -> CutSet:\\n    cutset_list = cuts.split_lazy(OUT_DIR, batch_size)\\n    new_cutset_list = []\\n    for i, cutset in enumerate(tqdm(cutset_list, desc=\"Processing cuts\")):\\n        text_list = [cut.supervisions[0].text if cut.supervisions else \"\" for cut in cutset]\\n        id_list = [cut.id for cut in cutset]\\n        duration = [cut.duration for cut in cutset]\\n        semantic_np = get_sentence_embeddings(\\n            text_list\\n        )\\n\\n        updated_cuts = []\\n        for cut, embedding in zip(cutset, semantic_np):\\n            cut = cut.with_custom(\"semantic_emb\", embedding.tolist())  # 如果是 numpy array\\n            updated_cuts.append(cut)\\n\\n\\n        new_cutset_list.append(CutSet.from_cuts(updated_cuts))\\n    merged_cuts = combine(*new_cutset_list)\\n    return merged_cuts\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def with_new_features(cuts: CutSet, batch_size = 100) -> CutSet:\n",
    "    cutset_list = cuts.split_lazy(OUT_DIR, batch_size)\n",
    "    new_cutset_list = []\n",
    "    for i, cutset in enumerate(tqdm(cutset_list, desc=\"Processing cuts\")):\n",
    "        text_list = [cut.supervisions[0].text if cut.supervisions else \"\" for cut in cutset]\n",
    "        id_list = [cut.id for cut in cutset]\n",
    "        duration = [cut.duration for cut in cutset]\n",
    "        semantic_np = get_sentence_embeddings(\n",
    "            text_list\n",
    "        )\n",
    "\n",
    "        updated_cuts = []\n",
    "        for cut, embedding in zip(cutset, semantic_np):\n",
    "            cut = cut.with_custom(\"semantic_emb\", embedding.tolist())  # 如果是 numpy array\n",
    "            updated_cuts.append(cut)\n",
    "\n",
    "\n",
    "        new_cutset_list.append(CutSet.from_cuts(updated_cuts))\n",
    "    merged_cuts = combine(*new_cutset_list)\n",
    "    return merged_cuts\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
